<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
	  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  <head>
    <title>TD Gammon revisited</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!--link rel="stylesheet" type="text/css" href="./ma.css" /-->
    <style>
      body {font-family: Comic Sans MS;}
      body {background-color: #33ffff;}
      h3 {color: Tomato;}
    </style>
  </head>
  <body>

    <p>

      Internship proposal.

    </p>

    <ul>
      <li>Title: TD-Gammon revisited</li>
      <li>Supervisor: <a href="https://philippe-preux.github.io/">Philippe Preux</a></li>
      <li>Duration: 5 to 6 months</li>
      <li>When: Spring-Summer 2020</li>
      <li>Where: <a href="http://sequel.lille.inria.fr/">SequeL</a>, Inria Lille, Villeneuve d'Ascq, France</li>
      <li>Expected background: master in CS, specialized in machine learning.</li>
      <li>Keywords: reinforcement learning, deep RL, games, backgammon, algorithms, experimental</li>
      <li>Context: <br/>
	Reinforcement learning is a sub-field of machine learning in which we aim at designing agents that learn to act. Acting usually involves performing a sequence of actions in order to achieve a goal. Examples are countless; games are good examples, like pacman or chess in which the player has to perform a series of action either to reach a maximal score, or to defeat his opponent. Applications of RL go way beyond games.
	<br/>
	Around the early 1990's, G. Tesauro created TD-Gammon which is a program that learned by RL to play Backgammon at expert level. The key ingredients are learning by temporal difference, and a neural network to represent the value function.
	<br/>
	Recently, this combination of RL and nets has been dubbed deep reinforcement learning, though there is usually nothing really deep in it. In particular TD-Gammon is really a single hidden layer neural network. Combining a somewhat deeper net with many tricks to make RL more efficient, RL is now world champion in chess, go, othello, shogi, ... and Atari games.
      </li>
      <li>What: <br/>
	The goal of this internship is:
	<ul>
	  <li>to reproduce Tesauro's original work,</li>
	  <li>perform a thorough experimental study of it,</li>
	  <li>think and explore how to use recent advances in RL to improve TD-Gammon,</li>
	  <li>perform the necessary experimental studies accordingly.</li>
	</li>
	Regarding the first objective, one of my interns in 2019 (Alessio Della Libera) re-implemented from scratch a Backgammon simulator, as well as TD-Gammon, and performed an initial experimental study of it. This internship will be based on this work. For the rest, it will be the intern's job to do it.</li>
    </ul>
    <li>Bibliography:
      <ul>
	<li><a href="http://incompleteideas.net/book/the-book.html">Sutton and Barto, Reinforcement Learning, an Introduction</a></li>
	<li>G. Tesauro, <a href="https://cling.csd.uwo.ca/cs346a/extra/tdgammon.pdf">Temporal Difference Learning and TD-Gammon</a>, CACM, 1995</li>
      </ul>
    </li>
    <li>Working environment: SequeL is a well-known research group in reinforcement learning and bandits. It is composed of 4 permanent researchers, 20+ PhD students, a couple of post-docs and engineers. SequeL provides a very rich and stimulating for doing cutting-edge research in RL.</li>
    </ul>

    <p>
      <a href="https://philippe-preux.github.io">Back to homepage.</a>
    </p>

</body>
</html>
