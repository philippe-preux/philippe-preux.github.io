<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
	  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  <head>
    <title>Model-based RL</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!--link rel="stylesheet" type="text/css" href="./ma.css" /-->
    <style>
      body {font-family: Comic Sans MS;}
      body {background-color: #33ffff;}
      h3 {color: Tomato;}
    </style>
  </head>
  <body>

    <p>

      Internship proposal.

    </p>

    <ul>
      <li>Title: Model-based RL</li>
      <li>Supervisor: <a href="https://philippe-preux.github.io/">Philippe Preux</a></li>
      <li>Duration: 5 to 6 months</li>
      <li>When: Spring-Summer 2020</li>
      <li>Where: <a href="http://sequel.lille.inria.fr/">SequeL</a>, Inria Lille, Villeneuve d'Ascq, France</li>
      <li>Expected background: master in CS, specialized in machine learning.</li>
      <li>Keywords: reinforcement learning, deep RL, games, backgammon, algorithms, experimental</li>
      <li>Context: <br/>
	Reinforcement learning is a sub-field of machine learning in which we aim at designing agents that learn to act. Acting usually involves performing a sequence of actions in order to achieve a goal. Examples are countless; games are good examples, like pacman or chess in which the player has to perform a series of action either to reach a maximal score, or to defeat his opponent. Applications of RL go way beyond games.
	<br/>
	RL algorithms are inherently slow to learn. One way to make them more efficient is to make them learn a model of their environment; this model is meant to be refined along learning and the RL agent may use this model in order to learn more efficiently. This idea is not new, dating back at least to the Sutton's Dyna architecture.
      </li>
      <li>What: <br/>
	The goal of this internship is:
	<ul>
	  <li>Study the litterature of model-based RL.</li>
	  <li>Explore new ideas. This exploration can be theoretical or algorithmic.</li>
	  <li>Perform an experimental assessment of the ideas.</li>
	</li>
    </ul>
    <li>Bibliography:
      <ul>
	<li><a href="http://incompleteideas.net/book/the-book.html">Sutton and Barto, Reinforcement Learning, an Introduction</a></li>
	<li>Sutton, ... Dyna ...</li>
      </ul>
    </li>
    <li>Working environment: SequeL is a well-known research group in reinforcement learning and bandits. It is composed of 4 permanent researchers, 20+ PhD students, a couple of post-docs and engineers. SequeL provides a very rich and stimulating for doing cutting-edge research in RL.</li>
    </ul>

    <p>
      <a href="https://philippe-preux.github.io">Back to homepage.</a>
    </p>

</body>
</html>
