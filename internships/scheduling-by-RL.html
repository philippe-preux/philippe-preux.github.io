<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
	  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  <head>
    <title>Task scheduling by reinforcement learning</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!--link rel="stylesheet" type="text/css" href="./ma.css" /-->
    <style>
      body {font-family: Comic Sans MS;}
      body {background-color: #33ffff;}
      h3 {color: Tomato;}
    </style>
  </head>
  <body>
    
    <p>
      
      Internship proposal.
      
    </p>
    
    <ul>
      <li>Title: task scheduling by reinforcement learning</li>
      <li>Supervisors: <a href="https://philippe-preux.github.io/">Philippe Preux</a>, <a href="https://nathangrinsztajn.github.io">Nathan Grinsztajn</a>, Olivier Beaumont, <a href="https://www.labri.fr/perso/ejeannot/">Emmanuel Jeannot</a>.</li>
      <li>Duration: 5 to 6 months</li>
      <li>When: Spring-Summer 2021</li>
      <li>Where: <a href="http://team.inria.fr/scool/">ScooL</a>, Inria Lille, Villeneuve d'Ascq, France, if sanitary conditions permit it, remotely otherwise. Could also be in Bordeaux.</li>
      <li>Keywords: reinforcement learning, task scheduling, high performance computing</li>
      <li>Context: <br/>
	In high performance computing (HPC), a task is split into a set of sub-tasks. The excutio of tasks usually depend on the result computed by other tasks. The set of tasks and their dependencies can be organized as a directed acyclic graph (DAG). Given such a DAG and a set of computational resources, the goal is to execute the set of tasks as fast as possible. To execute a DAG, a scheduler is in charge of properly choosing the next task to perform, and the resource to allocate to the task.
      </li>
      Scheduling tasks have been studied for decades now. There exists various approaches and algorithms for that. Reinforcement learning naturally fits to solve this sort of problems. However, until very recently, reinforcement learning has failed to provide a competitive approach. In 2020, we have been able to obtain very encouraging results using RL to solve such scheduling problems.
      <li>What: <br/>
	The goal of this internship is to dig further the approach we have proposed in 2020.
	<br/>
	Based on what we did yet, there is already a series of experiments to perform to better assess our approach; we have to go beyond the RL algorithm we experimented with (A2C). More generally, we expect that the intern will propose new ideas and test them. The goal of our work is really to obtain competitive schedulers that can be used in a real task scheduling HPC environment. 
      <li>Who: <br/>
	This internship is tailored as the final project of a master degree in computer science. We expect a strong background in reinforcement learning. Knowledge in either combinatorial optimization, or in HPC is a plus.
	<br/>
	The intern will read English w/o any difficulty and (s)he is able to work in English, make a scientific presentation in English, interact in English more generally. (We do not expect that the intern can speak French.)
      </li>
      <li>Bibliography:
	<ul>
	  <li><a href="https://hal.inria.fr/hal-03028981">N. Grinsztajn and O. Beaumont and E. Jeannot and Ph. Preux, Geometric deep reinforcement learning for dynamic DAG scheduling, Proc. ADPRL 2020.</a> </li>
	</ul>
      </li>
      <li>Working environment: this internship is proposed as part of a collaboration between 3 Inria research groups, HiePACS, Scool, and Tadaam. Scool is a well-known research group in reinforcement learning and bandits, located in Lille. Hiepacs and Tadaam are well-known research groups in HPC, located in Bordeaux.
      </li>
      <li>This internship can be the first step to a PhD on a related topic.</li>
    </ul>
      
      <p>
	<a href="https://philippe-preux.github.io">Back to homepage.</a>
      </p>
      
    </body>
  </html>
