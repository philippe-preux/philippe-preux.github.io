<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
	  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  <head>
    <title>RL for composite task</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!--link rel="stylesheet" type="text/css" href="./ma.css" /-->
    <style>
      body {font-family: Comic Sans MS;}
      body {background-color: #33ffff;}
      h3 {color: Tomato;}
    </style>
  </head>
  <body>

    <p>

      Internship proposal.

    </p>

    <ul>
      <li>Title: RL for composite task</li>
      <li>Supervisor: <a href="https://philippe-preux.github.io/">Philippe Preux</a></li>
      <li>Duration: 5 to 6 months</li>
      <li>When: Spring-Summer 2020</li>
      <li>Where: <a href="https://team.inria.fr/scool/">Scool</a>, Inria Lille, Villeneuve d'Ascq, France</li>
      <li>Expected background: master in CS, specialized in machine learning.</li>
      <li>Keywords: reinforcement learning, algorithms, experimental</li>
      <li>Context: <br/>
	Reinforcement learning is a sub-field of machine learning in which we aim at designing agents that learn to act. Acting usually involves performing a sequence of actions in order to achieve a goal. Examples are countless; games are good examples, like pacman or chess in which the player has to perform a series of actions either to reach a maximal score, or to defeat his opponent. Applications of RL go way beyond games.
	<br/>
	Many tasks consist in dealing with a set of more or less independant agents among which some resources have to shared in order to reach the goal. To illustrate this, let us take a very simple example, the game of small horses (petits chevaux in French). In this game, each player has to manage a set of pieces (horses); the pieces have to be moved from the pasture to the stable; in turn, each player rolls a dice and this gives the amount of cells the player has to move one of his pieces. The players compete to be the first to reach their goal (all their horses in their stable). So, each time a player rolls the dice, he has to allocate its result to one of its pieces in order that he would be the first to bring all his horses back to the stables. Hence, in this task, at each turn, the player has to decide which piece to move in order to reach a global objective. Obviously, a basic brute-force reinforcement learning can learn to solve this task by self-playing a large number of games. However, during this internship, we want to go beyond brute-force: brute-force is wasting an enormous amount of data, and it is so stupid (some call that "artificial" intelligence)
      </li>
      <li>What: <br/>
	The goal of this internship is:
	<ul>
	  <li>study the litterature of this problem,</li>
	  <li>explore new ideas. This exploration can be theoretical or algorithmic.</li>
	  <li>perform an experimental assessment of the ideas. For this, rather than small horses, we wil consider the ``barricade'' game which is essentially the same sort of game, though more complex (and more interesting to play for human beings). It might be useful to first implement a brute-force RL algorithm to solve it, to solve as a baseline solution.</li>
	</li>
    </ul>
    <li>Bibliography:
      <ul>
	<li>Sutton, Barto, <a href="http://incompleteideas.net/book/the-book.html">Reinforcement Learning, an Introduction</a>, 2nd edition, 2018</li>
	<li>Lapan, <i>Deep Reinforcement Learning Hands-On by</i>, Pakt, 2018</li>
      </ul>
    </li>
    <li>Working environment: Scool is a well-known research group in reinforcement learning and bandits. It is composed of 6 permanent researchers, 20+ PhD students, a couple of post-docs and engineers. Scool provides a very rich and stimulating for doing cutting-edge research in RL.</li>
    </ul>

    <p>
      <a href="https://philippe-preux.github.io">Back to homepage.</a>
    </p>

</body>
</html>
