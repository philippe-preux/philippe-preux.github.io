<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
	  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  <head>
    <title>L'Illusionniste Artificiel</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <!link rel="stylesheet" type="text/css" href="./ma.css" /-->
    <style>
      body {font-family: Comic Sans MS;}
      body {background-color: #33ffff;}
      h3 {color: Tomato;}
      h4 {color: LightSeaGreen;}
    </style>
  </head>

<body>

  <h3>L’Illusionniste Artificiel</h3>

  <h4>Que comprend un programme d'intelligence artificielle&nbsp;?</h4>

  <b>Rien du tout&nbsp;!</b>
  
  <p>

    L’assistante de l’illusionniste s’installe dans la grande boîte
posée horizontalement au milieu de la scène. Elle passe ses mains, ses
pieds à l’extérieur de la boîte, on voit son visage&nbsp;: elle est
bien là. L’illusionniste nous explique que l’on va vivre une
expérience extraordinaire&nbsp;; il se saisit d’un sabre et transperce
la boîte au niveau d’une jambe. Aucun cri, pas de sang qui coule. Un
autre sabre est enfoncé, puis un autre, puis un autre.  Visiblement,
l’assistante ne souffre pas. Et voilà que l’illusionniste fait
coulisser un élément central de la boîte&nbsp;: non contente d’être
transpercée de toute part, l’assistante est maintenant
démembrée. Encore un peu de suspens&nbsp;; les différents morceaux de
la boîte sont ré-alignés, les sabres retirés, la boîte ouverte et
l’assistante en ressort, en pleine forme. Je ne sais pas comment ce
tour est réalisé, mais je sais que je viens d’assister à une grande
expérience d’illusion&nbsp;: ce que j’ai cru voir ne s’est pas
réellement passé. Mais j’ai tellement envie d’y croire.

  </p>

  <p>

    Maintenant, lisons le court dialogue suivant&nbsp;:

    <br/>
    
    <img src="https://upload.wikimedia.org/wikipedia/commons/4/4e/ELIZA_conversation.jpg" width="500px" alt="Exemple d’un dialogue Eliza (from wikipedia)." />

  </p>


  <p>

    Ce que je viens de lire est le résultat d’une expérience datant du
début des années 1960, les débuts de l’intelligence artificielle. Ce
programme est facilement disponible&nbsp;: je peux moi-même interagir
avec lui et me rendre compte&nbsp;: <a href="https://www.masswerk.at/elizabot/">voici un lien</a> et <a href="https://www.cyberpsych.org/eliza/">un autre</a>. Ces systèmes fonctionnent en anglais parce que l'anglais se prête mieux à l'exercice que le français. Informaticien, je sais que ce dialogue
que je viens de lire ou même de tenir est réalisé par ELIZA, un
programme d’ordinateur&nbsp;: ELIZA n’est absolument pas intelligent
au sens où nous l’entendons. Mais j’ai tellement envie d’y croire. Ce
programme a tellement marqué les esprits que l’on nomme effet ELIZA la
« tendance à assimiler de manière inconsciente le comportement d'un
ordinateur à celui d'un être humain » (Source&nbsp;:
https://fr.wikipedia.org/wiki/Effet_ELIZA).

  </p>

  
  <p>

    Je peux donner d'autres exemples :

  </p>

  <ul>
    <!--li>des systèmes qui regroupent des groupes de musique qui se ressemblent.</li-->
    <li>Des moteurs de recherche qui trouvent des pages web qui contiennent ce que vous cherchez.</li>
    <li>Des systèmes de vision artificielle qui identifient les objets dans une scène.</li>
    <li>Des systèmes de vision artificielle qui déterminent une légende pour une image.</li>
    <li>Des systèmes de recommandation de produits.</li>
    <li>Des systèmes qui apprennent à dialoguer en langue naturelle.</li>
  </ul>

  <p>

    Les programmes informatiques qui réalisent ces tâches sont
exécutés par des circuits intégrés, microprocesseurs, qui ne font rien
d’autre que manipuler des bits à l’aide d’opérations de logiques
booléennes (et, ou, non). Informaticien, je sais tout cela, mais, j’ai
tellement envie d’y croire.</p>

  <p>

    
  </p>
  
  <p>

    Comment ça marche&nbsp;? Il y a deux grandes familles d’approches
en IA&nbsp;: IA symbolique et IA numérique. L’IA symbolique est basée
sur la logique&nbsp;: elle réalise des déductions à partir de faits et
de règles&nbsp;: si je sais que le fait A est vrai et que si le fait A
est vrai, alors je peux en déduire que le fait B est vrai, alors j’en
déduis B. C’est le raisonnement déductif classique. En disposant de
règles et de faits que l’on sait être vrais, on peut suivre le
raisonnement. Si on veut démontrer un certain fait, c’est-à-dire que
ce fait peut se déduire de cet ensemble de règles et de faits connus
initialement, on peut en principe déduire petit à petit tous les faits
qui se déduisent et ainsi, atteindre, ou pas, le fait visé. Quand on
réalise une démonstration en mathématiques, on procède ainsi. Le
nombre de faits que l’on peut déduire est typiquement très grand et
dans cet ensemble de faits déductibles, il faut trouver celui qui nous
intéresse&nbsp;; c’est le talent du mathématicien que d’imaginer les
faits qu’il est intéressant de démontrer et de trouver cette séquence
de déductions. De la même manière, à partir des règles d’un jeu comme
les échecs, on peut déduire toutes les configurations possibles et
ainsi, essayer d’atteindre une configuration gagnante&nbsp;; ce nombre
de configurations est considérable&nbsp;; après des dizaines d’années
d’efforts, l’ordinateur DeepBlue a battu le champion du monde d’échecs
en 1997 en pratiquant de cette manière. Un élément clé de cette
approche consiste à « élaguer » le raisonnement, c’est-à-dire éviter
de déduire des faits qui ne sont pas intéressants&nbsp;; c’est très
difficile en général, d’où le temps qu’il a fallu pour obtenir
DeepBlue qui s’appuyait sur des techniques d’élagage sophistiquées et,
surtout, sur une puissance de calcul considérable à cette époque.

  </p>
  <p> 

    L’IA numérique est basée sur la notion de corrélation
statistique. Je mesure une quantité au fil du temps&nbsp;; j’en mesure
une seconde. Je regarde ensuite comment varie l’une en fonction de
l’autre&nbsp;: si les deux croissent à peu près au même rythme, elles
sont corrélées&nbsp;; de même si l’une croît alors que l’autre décroît
et que la manière dont la première croît est à peu près la même que la
manière dont la seconde décroît, elles sont corrélées. En résumé, à
partir de la valeur de l’une, on peut déterminer la valeur de la
seconde, à peu près, par une simple relation linéaire que tous les
élèves apprennent en seconde (y = ax + b) . Ce type de relations nous
permet de réaliser des prédictions&nbsp;: prédire la valeur d’une
variable en connaissant une autre, ou prédire la valeur future d’une
série de mesures d’une certaine variable.  Bien sûr, la relation de
corrélation peut combiner plus de deux variables. L’exploitation de la
notion de corrélation donne accès à un mode de raisonnement puissant
qui est l’induction&nbsp;: à partir de quelques exemples, on induit
une règle générale, on généralise la connaissance. C’est en exploitant
cette notion de corrélation que les exemples précédents fonctionnent,
que Alpha Go est devenu champion du monde de go. Construits sur le
même principe, les programmes actuels d’échecs battent à plate couture
DeepBlue.

</p>

  <p>

    L'IA symbolique fait des raisonnements rigoureux, pas d’à peu
près. L'IA numérique fait de l’à peu près, pas de raisonnements
rigoureux.</p>

  
  <p>
								 
    Dans les deux types de programme d’IA, que l’on déduise ou que
l’on induise, l’ordinateur ne fait que réaliser une suite d’opérations
logiques booléennes extrêmement élémentaires, ces opérations n’étant
que la traduction exacte des instructions d’un programme&nbsp;: on le
voit, aucune « compréhension » ne se cache ici&nbsp;: comme je le dis
à mes étudiants qui me disent en séance de TP que leur programme ne
fait pas ce qu’ils attendent&nbsp;: leur programme fait exactement ce
qu’ils lui ont demandé de faire&nbsp;: le problème est qu’ils ont mal
expliqué à l’ordinateur ce qu’ils attendaient de lui, pas que
l’ordinateur décide de jouer un tour à mes étudiants.</p>

  
<p>

</p>

  <p>

    Les succès actuels de l’IA ne résultent donc absolument pas d’une
quelconque compréhension par l’ordinateur de son activité&nbsp;; ils
résultent uniquement de l’exécution extrêmement méthodique, ne
laissant la place à aucune surprise, sans réel effet du hasard, d’une
séquence de traitements booléens très élémentaires. En cela,
l’ordinateur se distingue fondamentalement d’un être humain qui peine
à réaliser rigoureusement une suite de déductions logiques, même
simple. On apprend à l’école aux enfants humains à raisonner
rigoureusement et <i>in fine</i>, à l’âge adulte, on peut constater
que peu d’humains arrivent à le faire vraiment dans leurs activités
quotidiennes, et même les mathématiciens, les scientifiques plus
généralement, pour lesquels le raisonnement est l’un des fondements de
leur activité professionnelle, commettent des erreurs de raisonnement
(on découvre encore régulièrement des erreurs dans des preuves
mathématiques datant de plusieurs siècles) dans des suite de
déductions bien simples par rapport à ce que réalisent les
ordinateurs. À l’opposé, encore très jeunes, tous les enfants ayant
des sens normalement développés voient sans avoir l’impression de
devoir faire un quelconque effort le chat qui est devant eux, voire
même s’il est caché en partie, en vrai, sur une photo, dans une image,
...

  </p>

  <p>
    
  </p>

  <p>

    On peut se demander si c’est grave que l’IA ne comprenne
rien. Pour moi, la réponse est oui et non. Non dans la mesure où la «
technologie IA » permet aujourd’hui de résoudre des tâches que l’on ne
savait pas résoudre il y a quelques années&nbsp;: c’est un outil que
l’on a découvert, que l’on étudie actuellement, qui permet de faire
des choses et qui n’a probablement pas fini de nous étonner.  Oui
c’est grave quand dans certains discours, certaines personnes parlent
de l’IA comme d’une entité intelligente, qui dépasse, dépassera
bientôt, ...  surpassera les humains. Et que ces discours sont repris
sans être critiqués et compris par des décideurs, leaders d’opinion,
gouvernants, ... pour exploiter et contrôler (politiquement ou
économiquement notamment) la société.

  </p>

  <p>
  </p>

  <p>

    On peut se demander aussi si l’IA comprendra un jour quelque
chose. Je ne sais pas. Je doute de le voir de mon vivant.

  </p>

  <p>

</p>


  <p>

    Enfin, une question que je trouve plus intéressante est de
savoir ce que l’IA nous apprend sur nous, humains.  Je trouve assez
fascinant que la simple manipulation de bits par des opérations
booléennes extrêmement élémentaires, dans des proportions colossales,
produise des artefacts qui fassent aussi bien illusion. Autant je suis
impressionné par l’illusionniste sur la scène, autant je suis fasciné
par certaines réalisations de l’IA. Mais voilà, quand je quitte la
salle de spectacle, je me retrouve dans la vraie vie où un sabre qui
transperce une personne ne la laisse pas indemne&nbsp;: après le rêve,
c’est le retour à la réalité.

  </p>

  <p>

    Les erreurs commises par les humains face à des situations sont
très intéressantes à étudier&nbsp;: il y a des tas de situations
(toutes ?) où un programme d’IA qui résoudrait la « même » tâche que
l’humain ne ferait pas d’erreur, ou pas la même erreur notamment parce
que justement, il ne comprend rien.  Et on le sait tous, les êtres
«&nbsp;parfaits&nbsp;» sont particulièrement pénibles et
inintéressants&nbsp;!
      
  </p>

  <p></p>

  <p>

    <font size="-1">&copy; Philippe Preux. Écrit en octobre 2020.</font>

  </p>

  <p>
    <a href="https://philippe-preux.github.io"><font size="-1">Back to homepage.</font></a>
  </p>

</body>
</html>
