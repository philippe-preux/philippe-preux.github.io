<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
<head>
  <title>Kernel methods and Reinforcement Learning (KRL) workshop</title>
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <style type="text/css">
    h1 {
	color: green;
   }
    h2 {
	color: blue;
   }
  </style>
</head>

<body>

<h1>KRL: Kernel machines and Reinforcement Learning workshop </h1>

<p>

To be held on June 29, 2006, at Carnegie-Mellon University,
Pittsburgh, USA as part of the workshop day at <a
href="http://www.icml2006.org" target="_top">ICML 2006</a>.

</p>

<h2>Attendance</h2>

<p>

Every participant to the ICML'2006 conference is welcome to attend and
participate to the workshop. This requires that the fee for the
workshops has been paid. For that, please refer to the <a
href="http://www.icml2006.org/icml2006/registration.html">ICML
registration page</a>.

<br/>
<br/>

On behalf of the presentations of submitted papers and invited
speeches, we want to keep the discussion very open to anyone who
wishes to express his/her opinion, as far as this is relevant with the
topic of the workshop. To let us somehow organize the day, and have a
sort of schedule, we kindly ask anyone who would like to attend to:

</p>

<ul>
  <li>send us an email</li>
  <li>tell us whether he/she wants a few minutes to express his/her
	point. In this case, please let us know very briefly the topic</li>
</ul>

<p>

Please, send emails to <kbd>philippe -dot- preux -at- univ-lille3
-dot- fr</kbd>

</p>

<h2>Main theme</h2>

<p>

Reinforcement Learning (RL) is an adaptive method for learning to make
good decisions in a complex, stochastic and partially unknown
environment.

<br/>
<br/>

In order to deal with large-scale RL problems, the functions of
interest (such as the value function or the policy, or a model of the
unknown state dynamics) must be approximately represented. Since the
quality of approximations directly influences the performance measures
of ultimate interest, the function approximation methods employed
should be sample-efficient whilst being able to deliver high quality
estimates at the same time. For instance, in Approximate Dynamic
Programming the performance of policies greedy with respect to
approximate value functions are bounded in terms of the
approximation's precision.

<br/>
<br/>

Thus real-world applications of RL need efficient function approximators. 

<br/>
<br/>

Kernel methods are at the heart of many modern machine learning
techniques. They make it possible to derive efficient algorithms that
work in function spaces of high representation power and come with
PAC-style theoretical results.

<br/>
<br/>

This workshop will be entirely dedicated to bridging
the gap between kernel methods and reinforcement learning.

<br/>
<br/>

Appropriate topics for papers include, but are not limited to:

</p>

<ul>
  <li>how to use kernel methods in RL?</li>
  <li>which kernel methods are the best to be used with RL?</li>
  <li>real-size applications of RL using kernel methods</li>
  <li>theoretical advances in RL thanks to a kernel-based approach</li>
</ul>

<h2>Schedule</h2>

<p>

This is the temptative schedule of the workshop day (as of June,
28<sup>th</sup>).

</p>

<ul>
  <li>Breakfast: 8 to 9</li>
  <li>Session 1: 9 to 10:50
    <ul>
      <li>Introduction</li>
      <li>Paper presentation + discussion:
	<ul>
          <li>M. Ghavamzadeh &amp; Y. Engel, <a href="./Ghavamzadeh-engel.pdf">Bayesian Policy Gradient</a></li>
          <li>N. Jong &amp; P. Stone, <a href="./jong-stone.pdf">Kernel based models for reinforcement learning</a>, <a href="./slides-jong.pdf">slides</a></li>
      <li>M. Maggioni about <i>Laplacian and wavelet bases for
	value function approximation and their connection to kernel
	methods</i>, <a href="./slides-maggioni.pdf">slides</a></li>
	</ul></li>
    </ul></li>
  <li>Coffee break: 10:50 to 11:20</li>
  <li>Invited speech: Y. Engel, <i>Gaussian Process Temporal Difference 
    Learning - Theory and Practice</i>,
    <a href="./slides-engel.pdf">slides</a></li>
  <li>Lunch 12:35 to 14:05</li>
  <li>Session 2: 14:05 to 15:45
    <ul>
      <li>Paper presentation + discussion
	<ul>
          <li>L. Chapel &amp; G. Deffuant, <a href="./chapel_deffuant.pdf">SVM viability controller active learning</a>, <a href="./slides-chapel.pdf">slides</a></li>
          <li>M. Loth, M. Davy, R. Coulom &amp; Ph. Preux, <a href="./loth_et_al.pdf">Equi-gradient Temporal Difference Learning</a>, <a href="./slides-loth.pdf">slides</a></li>
	</ul></li>
    </ul></li>
  <li>Coffee break: 15:45 to 16:15</li>
  <li>Various speakers + general discussion: 16:15 to 17:30<br/>
    The following people will present their current work (the list is still open!):
    <ul>
      <li>Drew Bagnell &amp; John Langford about <i>reduction
        techniques in RL</i></li> 
      <li>Rémi Munos &amp; Csaba Szepesvari about <i>A statistical
        learning theory approach to approximate dynamic
        programming</i>, <a href="./slides-munos.pdf">rémi's slides</a>, and <a href="./slides-szepesvari.pdf">csaba's ones</a></li> 
    </ul></li>
  <li>Closing remarks</li>
</ul>

<h2>Organizers</h2>

<ul>
  <li><a href="http://www-lagis.univ-lille1.fr/~davy/">Manuel
  Davy</a>, CNRS, <a href="http://www-lagis.univ-lille1.fr/">LAGIS</a>, École Centrale de Lille, &amp; <a href="http://www.grappa.univ-lille3.fr/SequeL">INRIA-Futurs</a>, France</li>
  <li><a href="http://www.cmap.polytechnique.fr/~munos/">Rémi
  Munos</a>, <a href="www.cmap.polytechnique.fr/">CMAP</a>, École Polytechnique, &amp; <a href="http://www.grappa.univ-lille3.fr/SequeL">INRIA-Futurs</a>, France</li>
  <li><a href="http://www.grappa.univ-lille3.fr/~ppreux">Philippe
  Preux</a>, <a href="http://www.lifl.fr">LIFL</a>, University of Lille 3, &amp; <a href="http://www.grappa.univ-lille3.fr/SequeL">INRIA-Futurs</a>, France</li>
  <li><a href="http://www.sztaki.hu/~szcsaba/">Csaba Szepesvari</a>,
  <a href="http://www.sztaki.hu/">Computer and Automation Research Institute</a> of the Hungarian Academy
  of Sciences, Hungary</li>
</ul>

<h2>Program commitee</h2>

<ul>
  <li>Drew Bagnell, CMU, USA</li>
  <li>Yaakov Engel, U. Alberta, Canada</li>
  <li>Michael Griebel, U. Bonn, Germany</li>
  <li>Michail Lagoudakis, Georgia Institute of Technology, USA</li>
  <li>Gabor Lugosi, Pompeu Fabra University, Spain</li>
  <li>Sridhar Mahadevan, U. Massachussets, USA</li>
  <li>Shie Mannor, Mc-Gill U., Canada</li>
  <li>Ron Meir, Technion, Israel</li>
  <li>Sean Meyn, U. Illinois, USA</li>
  <li>Doina Precup, Mc-Gill U., Canada</li>
  <li>Robert Schaback, U. Goettingen, Germany</li>
  <li>Jeff Schneider, CMU, USA</li>
  <li>Bill Smart, Washington University in St Louis, USA</li>
</ul>

<h2>Important dates</h2>

<ul>
  <li>call for paper issued now (18 march 2006)</li>
  <li>submission deadline: <strong>April 30, 2006</strong></li>
  <li>acceptance/rejection notification: May 21, 2006</li>
  <li>on-line proceedings available: June 9, 2006</li>
</ul>

<ul>
  <li>workshop day: June 29, 2006</li>
</ul>

<h2>Submission</h2>

<p>

We primarely expect original submissions. However, we will also accept
submissions of already accepted papers if the authors make it clear
that this is not an original submission. In the process of acceptence,
we will favor original submissions and accept resubmissions only if
there is enough time in the schedule.

</p>

<ul>
  <li> format: basically, the same format as for ICML proceedings except 
    that it indicates that the paper is for the KRL workshop. <a href="./latex4krl.tgz">the tarball is available here</a></li>
  <li>2 to 15 pages</li>
  <li>email a pdf file to <kbd>philippe -dot- preux -at- univ-lille3 -dot- fr</kbd></li>
</ul>

</body>
</html>
