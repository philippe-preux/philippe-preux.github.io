<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Classification supervisée avec un perceptron</title>
  <link href="https://philippe-preux.github.io/css/ma.css" 
	rel="stylesheet" type="text/css" media="all" />
  <link rel="shortcut icon" type="image/x-icon" 
	href="https://philippe-preux.github.io/img/site.ico" />
</head>

<body>
<div class="tpR">

  <h1>Classification supervisée avec un perceptron</h1>

  <p>

    En s'appuyant sur le TP sur le perceptron non linéaire, ce TP a pour objet de mettre en &oelig;uvre la méthodologie pour la classification supervisée.

    <br/>

    On utilise un perceptron dont la fonction d'activation est la tangente hyperbolique.
    
  </p>

  <h2>Points clés méthodologiques</h2>

  <p>

    Ce que nous avons fait jusqu'à maintenant a consisté à mettre au point l'algorithme de descente de gradient stochastique pour calculer les poids d'un perceptron.

    <br/>

    Disposant de cet algorithme, il s'agit maintenant de l'utiliser correctement. Ce n'est pas ce que nous fait dans le TP précédent. Pour cela, il y a quelques points méthodologiques à respecter impérativement&nbsp;:

  </p>

  <ol>
    <li>pour arrêter le calcul des poids, on doit utiliser une partie des exemples distincte des exemples que l'on utilise pour calculer les poids. On doit donc partitionner l'ensemble des exemples en deux parties&nbsp;:
      <ul>
	<li>l'ensemble d'entraînement est constitué d'exemples qui sont uniquement utilisés pour calculer les poids,</li>
	<li>l'ensemble de test est constitué d'exemples qui sont uniquement utilisés pour mesurer l'erreur de prédiction commise par le perceptron. Cette erreur est utilisée pour déterminer le moment d'arrêter le calcul des poids (la DGS).</li>
      </ul></li>
    <li>Durant le calcul des poids, les exemples doivent être parcourus dans un ordre aléatoire, qui change à chaque itération de la boucle principale de la DGS.</li>
  </ol>

  <p>

    Prendre en compte ces points permet de résoudre une tâche d'apprentissage supervisé.

  </p>

  <h2>Algorithme de calcul des poids</h2>

  <p>

    Pour calculer les poids, on utilise l'algorithme ci-dessous. C'est l'algorithme du TP précédent dans lequel ce qui change est indiqué <font color="red">en rouge</font>.

    <br/>

    Comme précédemment, on utilise les notations suivantes : on a un jeu d'exemples constitué de N données d'entrées et des N valeurs de sortie attendues. Chaque donnée est décrite par P attributs.

    <br/>

    On note X<sub>i</sub> la i<sup>è</sup> donnée et X<sub>i,j</sub> l'attribut j de la i<sup>è</sup> donnée. On note Y<sub>i</sub> la sortie attendue pour la i<sup>è</sup> donnée. Le i<sup>è</sup> exemple est donc le couple (X<sub>i</sub>, Y<sub>i</sub>). X est une matrice dont chaque ligne correspond à une donnée et chaque colonne correspond à un attribut. Y est un vecteur.

    <br/>

    On note E_train et E_test respectivement l'erreur de prédiction mesurée sur (X_train, Y_train) d'une part, sur (X_test, Y_test) d'autre part. Cette erreur est estimée par la proportion d'exemples dont l'étiquette est mal prédite par le perceptron.

  </p>

  <ol>
    <li>Centrer et réduire les exemples.</li>
    <li><font color="red">Découper le jeu d'exemple (X, Y) en un jeu d'entraînement noté (X_train, Y_train) et un jeu de test noté (X_test, Y_test).</font></li>
    <li>Initialiser les P poids avec une valeur quelconque.</li>
    <li><font color="red"><s>corrections = 1</s></font></li>
    <li><b>Tant-que</b> <font color="red">E_test diminue</font><b>:</b>
      <ol>
	<li><s>corrections = 0</s></li>
	<li><font color="red">Mélanger les exemples d'entraînement.</font></li>
	<li><b>Pour</b> chaque exemple (X_train<sub>i</sub>, Y_train<sub>i</sub>)<b>:</b>
	  <ol>
	    <li>on calcule la sortie s du perceptron pour cet exemple.</li>
	    <li>On en déduit la classe prédite&nbsp;: <b>si</b> s &ge; 1/2, <b>alors</b> classe.prédite = 1, <b>sinon</b> classe.prédite = 0.</li>
	    <li>d = classe.prédite - Y_train<sub>i</sub></li>
	    <li><b>Si</b> d est non nulle <b>alors</b>
	      <br/>
	      <ol>
		<li>biais = biais - &eta; d s (1 - s)</li>
		<li><s>corrections = corrections + |&eta; d (1 - s<sub>2</sub>)|</s></li>
		<li><b>Pour</b> chaque poids j <b>:</b>
		  <ul>
		    <li>p<sub>j</sub> = p<sub>j</sub> - &eta; d x<sub>i,j</sub> (1 - s<sub>2</sub>)</li>
		    <li><s>corrections = corrections + |&eta; d x<sub>i,j</sub> s (1 - s)|</s></li>
		  </ul>
		</li>
	      </ol>
	    </li>
	    </ol>
	    <li><font color="red">Calculer E_test.</font></li>
	  </li>
      </ol></li>
    </ol>
  
  <h2>Mise en &oelig;uvre de la méthodologie</h2>

  <p>

    Nous devons ajouter les deux éléments liés de méthodologie à l'algorithme de calcul des poids vu lors du TP précédant.

  </p>
  
  <h3>Partionnement du jeu d'exemples</h3>

  <p>

    Le partionnement du jeu d'exemples consiste à découper l'ensemble des exemples en deux sous-ensembes disjoints. On note <i>p</i> la proportion d'exemples utilisés pour mesurer
    
  </p>
  
  <h3>Parcours dans un ordre aléatoire des exemples</h3>

  <p>

  </p>

  <h2>Réalisation</h2>

  <p>

  </p>

  <h2>Reproductibilité expérimentale</h2>

  <p>

    Lorsque l'on utilise un programme qui utilise des nombres aléatoires, il faut impérativement faire en sorte que le résultat soit reproductible. Pour cela, il faut insérer un mécanisme qui garantit que l'on peut ré-exécuter le programme et que son comportement sera le même et qu'il fournira le même résultat à chaque exécution. Si on ne le fait pas, le programme peut donner des résultats différents à chaque exécution. C'est ennuyeux pour deux raisons&nbsp;:
    
  </p>

  <ul>
    <li>lors de la mise au point de votre programme et tant qu'il ne fonctionne pas correctement, si son fonctionnement change à chaque exécution, sa mise en point est très complexe. On vérifie beaucoup plus facilement le fonctionnement d'un programme qui donne toujours le même résultat à chacune de ses exécutions.</li>
    <li>D'un point de vue méthodologique expérimentale, il faut pouvoir reproduire un résultat. Exécuter un programme de classification supervisée revient à réaliser une expérience&nbsp;; celle-ci doit pouvoir être reproduite.</li>
  </ul>

  <p>

    Bien entendu, ce mécanisme qui permet la reproductibilité du comportement du programme n'empêche pas que le programme se comporte différemment à chacune de ses exécutions <b>si on le souhaite</b>. Ce que l'on veut, c'est maîtriser le comportement aléatoire du programme, pas l'empêcher.

    <br/>
    <br/>

    Dans un ordinateur, les nombres aléatoires ne sont pas générés de manière aléatoire, bien au contraire. Ils sont générés en utilisant une formule de récurrence qui produit un flux de nombres aléatoires. Pour être précis, on parle de nombres pseudo-aléatoires car justement ils ne sont pas aléatoires mais engendrer de manière très précise pour que la suite de nombres ainsi générée ait toutes les caractéristiques qu'aurait une séquence de nombres effectivement aléatoires.

    <br/>

    Dans tout raisonnement par récurrence, on a une règle qui permet de calculer le terme suivant et il y a le premier terme qui est fixé. Dans un générater de nombre pseudo-aléatoire, la récurrence est initialisé à l'aide d'une graine qui est un simple nombre entier&nbsp;; vous prenez le nombre que vous voulez, mais vous vous en rappeler.

    <br/>

    Très concrétement, tout cela se traduit dans votre programme par l'ajout de cette instruction&nbsp;:

  </p>

  <pre>rng = np.random.default_rng (123)</pre>

  <p>

    123 est la graine que j'ai choisie.

    <br/>

    Il faut placer cette instruction le plus tôt possible dans votre programme. Il faut avoir fait <kbd>import numpy as np</kbd> auparavant. Vous pouvez initialiser la graine juste après.

    <br/>
    <br/>

    Un petit exemple de son effet. <kbd>rng.integers (a, b)</kbd> génère un nombre compris entre -10 et 10. Si vous exécutez ce programme&nbsp;:
    
  </p>
  <pre>import numpy as np

print ("5 nombres pseudo-aléatoires :")
rng = np.random.default_rng (123)
for i in range(5):
    print (rng.integers (-10, 10))

print ("5 autres nombres pseudo-aléatoires :")
rng = np.random.default_rng (456)
for i in range(5):
    print (rng.integers (-10, 10))

print ("Les 5 premiers à nouveau :")
rng = np.random.default_rng (123)
for i in range(5):
    print (rng.integers (-10, 10))</pre>

  <p>

    vous obtenez la sortie&nbsp;:

  </p>

  <pre>5 nombres pseudo-aléatoires :
-10
3
1
-9
8
5 autres nombres pseudo-aléatoires :
-3
-1
-1
-2
-10
Les 5 premiers à nouveau :
-10
3
1
-9
8</pre>

  <p>

    Comme vous utilisez la même graine, vous êtes certain d'obtenir exactement le même résultat.

    <br/>

    En conclusion, ajoutez l'initialisation de la graine dans votre programme. Ainsi, le partitionnement du jeu d'exemples entre les exemples d'entraînement et exemples de test sera toujours le même. Si vous voulez changer ce partionnement, changez la valeur de la graine.
    
  </p>
  
  <h2>Pour finir</h2>

  <p>

    Le source de votre programme doit respecter les points suivants&nbsp;:
      
  </p>
  
  <ul>
    <li>il doit commencer par un commentaire indiquant son titre, son objet, ses auteurs, la date de réalisation.</li>
    <li>Que vous utilisiez des fonctions ou pas (ce n'est pas obligatoire), vous commentez votre programme avec parcimonie, là où c'est utile.</li>
    <li>Chaque fonction doit commencer par un commentaire indiquant au minimum ce que fait la fonction, le sens des paramètres, les pré-conditions et ce que la fonction retourne.</li>
    <li>Le type des paramètres des fonctions doit être indiqué, ainsi que le type de la valeur retournée.</li>
  </ul>
  
  <p>
    
    Pour finir, vous m'envoyez votre/vos script(s) par email, en mettant votre binôme en cc.
    
  </p>
  
</div>

</body>
</html>
