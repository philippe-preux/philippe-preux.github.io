<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Classification supervisée avec un perceptron</title>
  <link href="https://philippe-preux.github.io/css/ma.css"
	rel="stylesheet" type="text/css" media="all" />
  <link rel="shortcut icon" type="image/x-icon" 
	href="https://philippe-preux.github.io/img/site.ico" />
</head>

<body>
<div class="tpR">

  <h1>Classification supervisée avec un perceptron</h1>

  <p>

    En s'appuyant sur le TP sur le perceptron non linéaire, ce TP a pour objet de mettre en &oelig;uvre la méthodologie pour la classification supervisée.

    <br/>

    On utilise un perceptron dont la fonction d'activation est la tangente hyperbolique.
    
  </p>

  <h2>Points clés méthodologiques</h2>

  <p>

    Ce que nous avons fait jusqu'à maintenant a consisté à mettre au point l'algorithme de descente de gradient stochastique pour calculer les poids d'un perceptron.

    <br/>

    Disposant de cet algorithme, il s'agit maintenant de l'utiliser correctement. Ce n'est pas ce que nous fait dans le TP précédent. Pour cela, il y a quelques points méthodologiques à respecter impérativement&nbsp;:

  </p>

  <ol>
    <li>pour arrêter le calcul des poids, on doit utiliser une partie des exemples distincte des exemples que l'on utilise pour calculer les poids. On doit donc partitionner l'ensemble des exemples en deux parties&nbsp;:
      <ul>
	<li>l'ensemble d'entraînement est constitué d'exemples qui sont uniquement utilisés pour calculer les poids,</li>
	<li>l'ensemble de test est constitué d'exemples qui sont uniquement utilisés pour mesurer l'erreur de prédiction commise par le perceptron. Cette erreur est utilisée pour déterminer le moment d'arrêter le calcul des poids (la DGS).</li>
      </ul></li>
    <li>Durant le calcul des poids, les exemples doivent être parcourus dans un ordre aléatoire, qui change à chaque itération de la boucle principale de la DGS.</li>
  </ol>

  <p>

    Prendre en compte ces points permet de résoudre une tâche d'apprentissage supervisé.

  </p>

  <h2>Algorithme de calcul des poids</h2>

  <p>

    Pour calculer les poids, on utilise l'algorithme ci-dessous. C'est l'algorithme du TP précédent dans lequel ce qui change est indiqué <font color="red">en rouge</font>.

    <br/>

    Comme précédemment, on utilise les notations suivantes : on a un jeu d'exemples constitué de N données d'entrées et des N valeurs de sortie attendues (étiquettes). Chaque donnée est décrite par P attributs.

    <br/>

    On note X<sub>i</sub> la i<sup>è</sup> donnée et X<sub>i,j</sub> l'attribut j de la i<sup>è</sup> donnée. On note Y<sub>i</sub> la sortie attendue pour la i<sup>è</sup> donnée. Le i<sup>è</sup> exemple est donc le couple (X<sub>i</sub>, Y<sub>i</sub>). X est une matrice dont chaque ligne correspond à une donnée et chaque colonne correspond à un attribut. Y est un vecteur.

    <br/>

    On note N_train le nombre d'exemples composant X_train et N_test le nombre d'exemples composant X_test.

    <br/>

    On note E_train l'erreur de prédiction mesurée sur (X_train, Y_train) et on note E_test l'erreur mesurée sur (X_test, Y_test). Ces erreurs sont estimées par la proportion d'exemples dont l'étiquette est mal prédite par le perceptron.

  </p>

  <ol>
    <li>Centrer et réduire les exemples.</li>
    <li><font color="red">Découper le jeu d'exemples (X, Y) en un jeu d'entraînement noté (X_train, Y_train) et un jeu de test noté (X_test, Y_test).</font></li>
    <li>Initialiser les P poids avec une valeur quelconque.</li>
    <li><font color="red"><s>corrections = 1</s></font></li>
    <li><b>Tant-que</b> <font color="red">E_test diminue</font><b>:</b>
      <ol>
	<li><s>corrections = 0</s></li>
	<li><font color="red">Mélanger les exemples d'entraînement.</font></li>
	<li><b>Pour</b> chaque exemple (X_train<sub>i</sub>, Y_train<sub>i</sub>)<b>:</b>
	  <ol>
	    <li>on calcule la sortie s du perceptron pour cet exemple.</li>
	    <li>On en déduit la classe prédite&nbsp;: <b>si</b> s &ge; 1/2, <b>alors</b> classe.prédite = 1, <b>sinon</b> classe.prédite = 0.</li>
	    <li>d = classe.prédite - Y_train<sub>i</sub></li>
	    <li><b>Si</b> d est non nulle <b>alors</b>
	      <br/>
	      <ol>
		<li>biais = biais - &eta; d s (1 - s)</li>
		<li><s>corrections = corrections + |&eta; d (1 - s<sub>2</sub>)|</s></li>
		<li><b>Pour</b> chaque poids j <b>:</b>
		  <ul>
		    <li>p<sub>j</sub> = p<sub>j</sub> - &eta; d x<sub>i,j</sub> (1 - s<sub>2</sub>)</li>
		    <li><s>corrections = corrections + |&eta; d x<sub>i,j</sub> s (1 - s)|</s></li>
		  </ul>
		</li>
	      </ol>
	    </li>
	    </ol>
	    <li><font color="red">Calculer E_test.</font></li>
	  </li>
      </ol></li>
    </ol>
  
  <h2>Les jeux d'exemples basés sur les <i>iris</i></h2>

  <p>

    Le jeu d'exemples <i>iris</i> est constitué de fleurs d'iris appartenant à 3 espèces différentes&nbsp;: <i>Setosa</i>, <i>Versicolor</i>, <i>Virginica</i>. L'objectif est de déterminer l'espèce (= la classe) d'une fleur étant données ses caractéristiques&nbsp;: longueur et largeur des sépales, longueur et largeur des pétales. Chaque donnée est donc un vecteur de 4 nombres. La figure ci-dessous représente les exemples de ces trois classes dans le plan longueur x largeur des pétales&nbsp: les <i>Setosa</i> en bleu, les <i>Versicolor</i> en vert, les <i>Virginica</i> en rouge.

    <br/>

    <img src="iris.png" width="300pt" alt="Répartition des 3 espèces d'iris." />

    <br/>

    Puisqu'un perceptron permet de séparer deux classes seulement (pas trois, un perceptron réalise une tâche de classification binaire), dans le TP précédent et celui-ci on transforme ce problème à 3 classes en un problème à 2 classes. Ou plutôt, en 2 problèmes différents&nbsp;: si on veut prédire les <i>Setosa</i> par rapport aux deux autres espèces, le problème est linéairement séparable&nbsp;: si on veut prédire les <i>Virginica</i> par rapport aux deux autres, le problème n'est pas linéairement séparable&nbsp;: sur la figure ci-dessus, on voit que les rouges (<i>Virgicinica</i>) se mélangent avec les verts (<i>Versicolor</i>).

    <br/>

    Dans le premier cas, il faut que l'étiquette à prédire indique si la donnée est un iris <i>Setosa</i> ou pas&nbsp;; dans le second cas, il faut que l'étiquette indique si la donnée est un iris <i>Virginica</i> ou pas.

    <br/>
    
    Dans ce TP, on va donc utiliser deux étiquettes, l'une indiquant que la donnée est un <i>Setosa</i>, l'autre que la donnée est un <i>Virginica</i>. Pour cela, on effectue ce qui suit&nbsp;:

  </p>
  
  <pre>N = len (iris.target) # le nombre d'exemples
Y_setosa = np.zeros ((N))      # Y_setosa est un tableau contenant N 0
Y_virginica = np.zeros ((N))   # idem pour Y_virginica
for i in range (len (iris.target)):
    if iris.target [i] == 0:
        Y_setosa [i] = 1
    else:
        Y_setosa [i] = 0
    if iris.target [i] == 2:
        Y_virginica [i] = 1
    else:
        Y_virginica [i] = 0</pre>

  <p>
    
    Ensuite, si on veut prédire les <i>Setosa</i>, on affecte <kbd>Y_setosa</kbd> à <kbd>sorties</kbd>. Si on veut prédire les <i>Virginica</i>, on affecte <kbd>Y_virginica</kbd> à <kbd>sorties</kbd>.

  </p>
  
  <h2>Mise en &oelig;uvre de la méthodologie</h2>

  <p>

    Nous devons ajouter les deux éléments liés de méthodologie à l'algorithme de calcul des poids vu lors du TP précédant.

  </p>
  
  <h3>Partionnement du jeu d'exemples</h3>

  <p>

    Le partionnement du jeu d'exemples consiste à découper l'ensemble des exemples (X, Y) en deux sous-ensembles disjoints. Une proportion <i>p</i> d'exemples constitue (X_test, Y_test), les autres constituant (X_train, Y_train).

    <br/>

    On peut s'y prendre de deux manières&nbsp;: le faire soi-même ou utiliser une fonction qui réalise ce découpage.

    <br/>

    Je vous encourage très fortement à réaliser ce découpage vous-même car c'est très facile à faire (en particulier, les étudiants qui réalisent les TPs rapidement doivent effectuer ce découpage en codant eux-mêmes ce traitement&nbsp;: c'est juste une boucle).

    <br/>

    Une fonction est disponible dans le paquetage <kbd>sklearn</kbd> qui réalise ce découpage. Elle se nomme <kbd>train_test_split()</kbd>.
    Pour l'utiliser, on écrit d'abord&nbsp;:

  </p>
  
  <pre>import numpy as np
graine = int ("Perceptron", base=36)%2**31
gnpa = np.random.default_rng (graine)</pre>

  <p>
    
    <i>Strico senso</i>, ces lignes ne sont pas indispensables pour effectuer le partionnement du jeu d'exemples. Ces lignes garantissent qu'à chaque fois que vous lancez votre programme, il partitionne le jeu d'exemples exactement de la même manière. C'est un point important sur lequel nous revenons <a href="#repro">plus bas</a>.

    <br/>

    Maintenant, on peut partitionner le jeu d'exemples. On fait comme suit. Supposons que p=0,2, on écrit&nbsp;:

  </p>
  
  <pre>from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split (X, Y, test_size = 0.2, random_state = np.random.RandomState (graine))</pre>

  <p>
    
    On a désormais partitionné le jeu d'exemples (X, Y) en un jeu d'entraînement (X_train, Y_train) et un jeu d'exemples (X_test, Y_test). Le premier est composé de 80% des exemples de (X, Y), le second est composé des 20% restants. Sur la figure ci-dessous, j'indique avec des points plus gros les exemples de test. Il faut bien garder à l'esprit que ces exemples ne sont pas utilisés pour calculer les poids, seuls les petits points le sont.
    
    <br/>

    <img src="./train_test.png" width="300pt" alt="Les exemples d'iris où le jeu de test est indiqué par des points plus gros." />

    <br/>

    <font size="-5">Si vous voulez reproduire ce graphique avec des gros points et des petits, il faut vous inspirez de la fonction <kbd>debut_figure()</kbd>&nbsp;: dans la fonction <kbd>scatter()</kbd>, le paramètre <kbd>s = 2</kbd> indique la surface des points. Il suffit donc d'afficher les exemples d'entraînement avec <kbd>s = 2</kbd> et les exemples de test avec une valeur de <kbd>s</kbd> plus grande.</font>

    <br/>

  </p>
  
  <h3>Parcours des exemples dans un ordre aléatoire</h3>

  <p>

    Pour parcourir aléatoirement les exemples, il suffit d'égrener leurs indices dans un ordre aléatoire. Pour cela, on peut écrire&nbsp;:

  </p>
  
  <pre>N_train = len (Y_train)
permutation = gnpa.choice (np.arange (N_train), N_train, replace = False)</pre>

  <p>
    
    Il faut avoir préalablement importer le paquetage <kbd>numpy</kbd>.
    
    <br/>

    <kbd>permutation</kbd> contient une permutation des entiers de 0 à <kbd>N_train - 1</kbd>.

    <br/>

    Ensuite dans le corps de la boucle, il suffit de remplacer la variable <kbd>i</kbd> par <kbd>permutation [i]</kbd> et les exemples seront parcourus dans un ordre aléatoire. En calculant une nouvelle permutation à chaque itération de la DGS, le parcours des exemples d'entraînement sera différent à chaque itération de la DGS.

  </p>

  <h2>Réalisation</h2>

  <h3>Application aux iris&nbsp;: cas de deux classes linéairement séparables</h3>

  <p>

    Mettre en &oelig;uvre toute cette démarche sur le jeu de données iris utilisé dans le TP précédent.

    <br/>

    Attention&nbsp;: vous entrez dans la manipulation d'un type d'algorithmes qu'il n'est pas toujours facile de faire fonctionner comme on le voudrait. Quand ça ne marche pas, il faut bien réfléchir à ce que l'on fait, vérifier que le programme fait bien ce que l'on croit, ou espére, qu'il fait&nbsp;: il faut mener l'enquête jusqu'à comprendre ce qui ne va pas, le corriger et le faire fonctionner. En particulier, déterminer quand il faut arrêter les itérations de la DGS n'est pas si simple qu'on pourrait l'espérer. On voit cela maintenant.

    <br/>
    <br/>

    On va commencer par calculer les poids d'un perceptron qui sépare les <i>Setosa</i> des deux autres espèces&nbsp;: ce problème est linéairement séparable, ce doit être facile. On va donc utiliser les étiquettes stockées dans <kbd>Y_setosa</kbd>.

    <br/>

    Rédigez votre programme en mettant bout à bout tout ce que j'ai expliqué. Vous itérez tant que l'erreur de test E_test diminue.

    <br/>
    
    Pour vous donner quelques points de repères&nbsp;: au bout de quelques itérations, E_test ne diminue plus donc le programme s'arrête. E_train et E_test sont non nuls. Les poids correspondent à cette droite&nbsp;:

    <br/>

    <img src="./expe1.png" width="300pt" alt="Expérience 1 : le perceptron ne sépare pas les deux classes." />

    <br/>

    Si vous êtes étonné ou déçu, c'est normal&nbsp;: on s'attend à ce que le perceptron prédise correctement la classe et il ne le fait pas. Pourtant, ça devrait marcher. Avant de lire la suite, il est utile de réfléchir à ce qui peut ne pas bien se passer.

    <br/>
    <br/>

    Maintenant que <b>vous avez réfléchi pendant plusieurs minutes</b>, vous pouvez lire la suite. Néanmoins, si vous avez eu une ou des idées de ce qui peut ne pas bien fonctionner et causer cet étonnement ou cette déception, avant de lire la suite, testez vos idées&nbsp;: modifiez votre programme et voyez si ça améliore le résultat.

    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>
    <br/>

    La raison de l'échec est que la DGS s'est arrêtée trop tôt. Les poids du perceptron sont corrigés en utilisant le jeu d'entraînement, pas le jeu de test. Aussi, ce n'est pas parce que l'on modifie les poids que l'erreur de test diminue. Ce n'est pas parce E_test ne diminue pas d'une itération à la suivante qu'il ne pourrait pas le faire si on itère un peu plus car à chaque itération, les poids sont corrigés à l'aide des exemples d'entraînement et cela peut faire diminuer E_test.

    <br/>

    Pour ne pas s'arrêter trop tôt, on pourrait se dire que si E_test ne diminue pas, on va encore réaliser 10 itérations (10 est juste une valeur prise en exemple) et si décidément E_test ne diminue pas, on s'arrête.

    <br/>

    En pratiquant ainsi, mon programme effectue une vingtaine d'itérations et trouve finalement cette droite&nbsp;:

    <br/>

    <img src="./expe2.png" width="300pt" alt="Expérience 2 : le perceptron ne toujours sépare pas les deux classes, mais il a fait des progrès." />

    <br/>

    Comparons-la à la précédente&nbsp;: c'est mieux. Par ailleurs, si votre programme affiche E_test à chaque itération du tant-que de la DGS, vous pouvez constater qu'après avoir stagné, elle a continué de diminuer.

    <br/>

    On est sur la bonne voie. Si j'autorise E_test à stagner encore plus longtemps, j'obtiens la séparation des deux classes&nbsp;:
    
    <br/>

    <img src="./expe3.png" width="300pt" alt="Expérience 3 : le perceptron sépare Setosa des autres iris. Un exemple d'entraînement est mal classé." />

    <br/>

    On voit que l'un des exemples bleus est mal prédit&nbsp;: c'est un exemple d'entraînement aussi la DGS n'en tient pas compte pour s'arrêter&nbsp;: seuls les exemples de test sont utilisés pour déterminer l'arrêt du tant-que.
    Si cet exemple était dans le jeu de test, les itérations se poursuivraient.

    <br/>

    Si on continue encore les itérations, cet exemple d'entraînement est bien prédit lui-aussi car les poids continuent d'être corrigés. J'obtiens cela&nbsp;:

    <br/>

    <img src="./expe4.png" width="300pt" alt="Expérience 4 : le perceptron sépare Setosa des autres iris, y compris les exemples d'entraînement." />

    <br/>

  </p>

  <h3>Application aux iris&nbsp;: cas de deux classes non linéairement séparables</h3>

  <p>

    On considère maintenant le problème de prédire les <i>Virginica</i> par rapport aux autres iris. Pour cela, vous utilisez les étiquettes de Y_virginica.

    <br/>

    Refaites tout ce que l'on vient de faire avec ces étiquettes.

    <br/>

    Dans les mêmes conditions que ci-dessus, j'obtiens les 4 figures ci-dessous&nbsp;:

    <br/>

    <img src="./expe5.png" width="300pt" alt="Expérience 5 : séparation des Virginica." />
    <img src="./expe6.png" width="300pt" alt="Expérience 5 : séparation des Virginica." />
    <img src="./expe7.png" width="300pt" alt="Expérience 5 : séparation des Virginica." />
    <img src="./expe8.png" width="300pt" alt="Expérience 5 : séparation des Virginica." />

    <br/>
    <br/>

    On pourrait se dire qu'après tout, pourquoi compliquer les choses et pourquoi ne pas tout simplement réaliser 100 itérations (par exemple) du corps de la boucle tant-que. Modifiez votre programme pour le faire et exécutez-le. Il est intéressant de tracer E_train et E_test au fil des itérations. J'obtiens cela&nbsp;:
    
    <br/>

    <img src="./Erreurs.png" width="300pt" alt="E_train et E_test au fil de 100 itérations de DGS." />
    
    <br/>

    Sur ce graphique, on voit qu'au bout d'une trentaine d'itérations, E_test augmente&nbsp;! Cela signifie que l'on a fait trop d'itérations&nbsp;: le perceptron est en situation de sur-apprentissage, situation qu'il faut impérativement éviter.

    <br/>

    Conclusion&nbsp;: comme on ne sait jamais à l'avance quand le sur-apprentissage va survenir, on ne peut pas faire de boucle pour et on a besoin d'une boucle tant-que. Et savoir quand arrêter cette boucle tant-que n'est pas si simple.

  </p>

  <h2 id="repro">Reproductibilité expérimentale</h2>

  <p>

    Lorsque l'on utilise un programme qui utilise des nombres aléatoires, il faut impérativement faire en sorte que le résultat soit reproductible. Pour cela, il faut insérer un mécanisme qui garantit que l'on peut ré-exécuter le programme et que son comportement sera le même et qu'il fournira le même résultat à chaque exécution. Si on ne le fait pas, le programme peut donner des résultats différents à chaque exécution. C'est ennuyeux pour deux raisons&nbsp;:
    
  </p>

  <ul>
    <li>lors de la mise au point de votre programme et tant qu'il ne fonctionne pas correctement, si son fonctionnement change à chaque exécution, sa mise en point est très complexe. On vérifie beaucoup plus facilement le fonctionnement d'un programme qui donne toujours le même résultat à chacune de ses exécutions.</li>
    <li>D'un point de vue méthodologique expérimentale, il faut pouvoir reproduire un résultat. Exécuter un programme de classification supervisée revient à réaliser une expérience&nbsp;; celle-ci doit pouvoir être reproduite.</li>
  </ul>

  <p>

    Bien entendu, ce mécanisme qui permet la reproductibilité du comportement du programme n'empêche pas que le programme se comporte différemment à chacune de ses exécutions <b>si on le souhaite</b>. Ce que l'on veut, c'est maîtriser le comportement aléatoire du programme, pas l'empêcher.

    <br/>
    <br/>

    Dans un ordinateur, les nombres aléatoires ne sont pas générés de manière aléatoire, bien au contraire. Ils sont générés en utilisant une formule de récurrence qui produit un flux de nombres qui semblent aléatoires au fil de ses itérations. Pour être précis, on parle de nombres pseudo-aléatoires car justement ils ne sont pas aléatoires mais engendrés de manière très précise pour que la suite de nombres ainsi générée ait toutes les caractéristiques qu'aurait une séquence de nombres effectivement aléatoires.

    <br/>

    Dans tout raisonnement par récurrence, on a une règle qui permet de calculer le terme suivant et il y a le premier terme qui est fixé. Dans un générateur de nombres pseudo-aléatoires, la récurrence est initialisée à l'aide d'une graine qui est un simple nombre entier&nbsp;; vous prenez le nombre que vous voulez, mais vous vous en rappelez.
    Plus haut, on a effectué l'instruction <kbd>graine = int ("Perceptron", base=36)%2**31</kbd>. C'est une manière un peu sophistiquée de calculer une graine &nbsp;; on pourrait tout aussi bien écrire <kbd>graine = 123</kbd>. En effet, <kbd>int ("Perceptron", base=36)%2**31</kbd> transforme une chaîne de caractères en un entier.

    
    <br/>

    Très concrétement, tout cela se traduit dans votre programme par l'ajout de&nbsp;:

  </p>

  <pre>graine = int ("Perceptron", base=36)%2**31  # ou graine = un entier
gnpa = np.random.default_rng (graine)</pre>

  <p>

    Il faut placer cette instruction le plus tôt possible dans votre programme. Il faut avoir fait <kbd>import numpy as np</kbd> auparavant. Vous pouvez initialiser la graine juste après.

    <br/>
    <br/>

    Un petit exemple de son effet. <kbd>gnpa.integers (a, b)</kbd> génère un nombre compris entre -10 et 10. Si vous exécutez ce programme&nbsp;:
    
  </p>
  <pre>import numpy as np

print ("5 nombres pseudo-aléatoires :")
graine = 123
gnpa = np.random.default_rng (graine)
for i in range(5):
    print (gnpa.integers (-10, 10))

print ("5 autres nombres pseudo-aléatoires :")
gnpa = np.random.default_rng (456)
for i in range(5):
    print (gnpa.integers (-10, 10))

print ("Les 5 premiers à nouveau :")
gnpa = np.random.default_rng (graine)
for i in range(5):
    print (gnpa.integers (-10, 10))</pre>

  <p>

    vous obtenez la sortie&nbsp;:

  </p>

  <pre>5 nombres pseudo-aléatoires :
-10
3
1
-9
8
5 autres nombres pseudo-aléatoires :
-3
-1
-1
-2
-10
Les 5 premiers à nouveau :
-10
3
1
-9
8</pre>

  <p>

    Comme vous utilisez les mêmes graines que moi, vous obtenez le même résultat. Si vous changez la valeur affectée à <kbd>graine</kbd>, vous obtiendrez d'autres nombres.

    <br/>

    En conclusion, ajoutez l'initialisation de la graine dans votre programme. Ainsi, le partitionnement du jeu d'exemples entre les exemples d'entraînement et les exemples de test sera toujours le même. Si vous voulez changer ce partionnement, changez la valeur de la graine.

    <br/>

    Comparez le résultat obtenu en exécutant votre programme avec des graines différentes.

  </p>

  <h2>Travail en autonomie</h2>

  <p>

    Il y a trois classes/espèces d'iris. Un perceptron peut seulement distinguer deux classes. En utilisant deux perceptrons qui prédisent chacun une certaine classe et en combinant leurs prédictions pour une certaine donnée, pouvez-vous prédire les 3 classes&nbsp;? Si oui faites-le. Sinon, réfléchissez encore un peu.

    <br/>

    À la suite de ce que l'on a fait plus haut, les quelques lignes suivantes peuvent être vous être utiles&nbsp;:
    
  </p>

    <pre>Y_versicolor = np.zeros ((N))
for i in range (len (iris.target)):
    if iris.target [i] == 1:
        Y_versicolor [i] = 1
    else:
        Y_versicolor [i] = 0</pre>

  <h2>Pour finir</h2>

  <p>

    Le source de votre programme doit respecter les points suivants&nbsp;:
      
  </p>
  
  <ul>
    <li>il doit commencer par un commentaire indiquant son titre, son objet, ses auteurs, la date de réalisation.</li>
    <li>Vous commentez votre programme avec parcimonie, là où c'est utile.</li>
    <li>Chaque fonction doit commencer par un commentaire indiquant au minimum ce que fait la fonction, le sens des paramètres, les pré-conditions et ce que la fonction retourne.</li>
    <li>Le type des paramètres des fonctions doit être indiqué, ainsi que le type de la valeur retournée.</li>
  </ul>
  
  <p>
    
    Pour finir, vous m'envoyez votre/vos script(s) par email, en mettant votre binôme en cc.
    
  </p>
  
</div>

</body>
</html>
