<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Recherche des poids d'un perceptron non linéaire</title>
  <link href="https://philippe-preux.github.io/css/ma.css" 
	rel="stylesheet" type="text/css" media="all" />
  <link rel="shortcut icon" type="image/x-icon" 
	href="https://philippe-preux.github.io/img/site.ico" />
</head>

<body>
<div class="tpR">

  <h1>Recherche des poids d'un perceptron non linéaire</h1>

  <p>

    Ce TP reprend le TP précédent mais il est cette fois appliqué à un perceptron dont la fonction d'activation est une fonction sigmoïde.

    <br/>

    Comme en cours, on considère un perceptron réel à sortie réelle. La fonction d'activation est soit la fonction logistique, soit la fonction tangente hyperbolique.

  </p>

  <h2>Fonction d'activation logistique</h2>
  
  <h3>DGS pour calculer les poids d'un perceptron à fonction d'activation logistique</h3>
  
  <p>

    On adapte la DGS vue dans le TP précédent à la fonction d'activation logistique. Ci-dessous, j'indique ce qui change en <font color="red">rouge</font>.

  </p>

  <ul>
    <li>On a un jeu d'exemples constitué de N données d'entrées et des N valeurs de sortie attendues. Chaque donnée est décrite par P attributs.
      <br/>
      On note x<sub>i</sub> la i<sup>è</sup> donnée et x<sub>i,j</sub> l'attribut j de la i<sup>è</sup> donnée. On note y<sub>i</sub> la sortie attendue pour la i<sup>è</sup> donnée. Le i<sup>è</sup> exemple est donc le couple (x<sub>i</sub>, y<sub>i</sub>).</li>
    <li>On effectue la descente de gradient stochastique&nbsp;:
      <ol>
	<li><font color="red">center et réduire les exemples.</font></li>
	<li>Initialiser les P poids avec une valeur quelconque.</li>
	<li><font color="red">corrections = 1</font></li>
	<li><b>Tant-que</b> <font color="red">|corrections| &gt; &epsilon;</font><b>:</b>
	  <ol>
	    <li><font color="red">corrections = 0</font></li>
	    <li><b>Pour</b> chaque exemple x<sub>i</sub><b>:</b>
	      <ol>
		<li>on calcule la sortie s du perceptron pour cet exemple.</li>
		<li><font color="red">On en déduit la classe prédite&nbsp;: <b>si</b> s &ge; 0, <b>alors</b> classe.prédite = 1, <b>sinon</b> classe.prédite = 0.</font></li>
		<li>d = <font color="red">classe.prédite</font> - y<sub>i</sub>
		<li><b>Si</b> d est non nulle <b>:</b>
		  <br/>
		  <ol>
		    <li>biais = biais - &eta; d <font color="red">s (1 - s)</font></li>
		    <li><font color="red">corrections = corrections + |&eta; d s (1 - s)|</font></li>
		    <li><b>Pour</b> chaque poids j <b>:</b>
		      <ul>
			<li>p<sub>j</sub> = p<sub>j</sub> - &eta; d x<sub>i,j</sub><font color="red">s (1 - s)</font></li>
			<li><font color="red">corrections = corrections + |&eta; d x<sub>i,j</sub> s (1 - s)|</font></li>
		      </ul>
		    </li>
		  </ol>
		</li>
		</ol>
	      </li>
	  </ol></li>
      </ol></li>
    <li>C'est fini.</li>
    </ul>

    <p>

      Nous allons écrire le programme en python qui fait cela. Nous allons introduire un certain nombre de raffinements par rapport à ce que nous avions fait dans le TP précédent.

    </p>

    <h3>Quelques éléments pour la mise en &oelig;uvre</h3>

    <p>

      On précise quelques points nouveaux concernant la DGS.

    </p>
    
    <h4>Matrice de données</h4>

    <p>

    Dans les TPs précédents, nous avons considéré que les données sont contenues dans une liste. Dans la réalité, on les stocke dans une matrice dans laquelle chaque ligne correspond à une donnée et chaque colonne à un attribut.

    <br/>

    Dans le TP précédent, quand nous avons utilisé le jeu de données iris, celles-ci étaient stockées dans une matrice.

    <br/>

    </p>

    <h4>Classe prédite</h4>

    <p>

      Avec une fonction d'activation sigmoïde, la sortie du perceptron prend une valeur dans l'intervalle ]0, 1[. On veut interpréter cette valeur comme&nbsp;: si elle est inférieure à 0,5, cela signifie que le perceptron prédit la classe 0 pour la donnée placée en entrée&nbsp;; si cette valeur est &ge; 0,5, c'est que le perceptron prédit la classe 1.

      <br/>

      Il faut donc transformer la valeur en sortie du perceptron en un 0 ou un 1 pour povuoir comparer la prédiction du perceptron avec l'étiquette de l'exemple.
      
    </p>

    <h4>Centrer et réduire les attributs des données</h4>

    <p>

      On l'a vu en cours, centrer un attribut signifie retirer la moyenne à chacune de ses valeurs et réduire consiste à diviser l'attribut centré par l'écart-type de l'attribut centré.

      <br/>

      Cette opération est essentielle si on veut que la DGS fonctionne bien.

      <br/>

      On peut écrire soi-même une fonction pour le faire. C'est un bon exercice.

      <br/>

      Cette opération est tellement importante qu'elle est déjà codée. On fait comme cela sur l'exemple des iris&nbsp;:

    <p>
<pre># on charge le jeu de données iris (cf. TP précédent)
from sklearn import datasets
iris = datasets.load_iris()
entrées_iris = iris.data[:,2:4]

# on centre et on réduit comme suit
from sklearn.preprocessing import StandardScaler  
scaler = StandardScaler ()
scaler.fit (entrées_iris) # cette instruction indique que l'on veut centrer et réduire les données se trouvant dans matrice dénommé entrées_iris.
entrées = scaler.transform (entrées_iris) # cette instruction effectue le centrage et la réduction.</pre>

    <p>

      <kbd>entrées</kbd> est une matrice qui contient les iris décrits par leurs 4 attributs centrés et réduits.

    </p>

    <h4>Fonction d'activation</h4>

    <p>

      Il est utile de définir une fonction <kbd>logistique (v)</kbd> qui renvoie la valeur de la fonction logistique appliquée au potentiel <kbd>v</kbd>.

    </p>

    <h4>&eta; et &epsilon;</h4>

    <p>

      On peut prendre &eta; = 0,01. &epsilon; doit être petit, 10<sup>-8</sup> par exemple.

    </p>
    
    <h3>Réalisation</h3>
    
    <p>

      On a maintenant tous les ingrédients pour réaliser la DGS. Pour s'assurer que le programme fonctionne bien dans un cas simple, on commence par le cas où le perceptron peut correctement calculer la sortie attendue. Une fois assurés que le programme fonctionne bien dans ce cas-là, on vérifiera qu'il fonctionne aussi lorsqu'il ne peut pas calculer correctement la valeur attendue quelle que soit la donné en entrée.

      <br/>

      Comme dans le TP précédent, vous utiliserez les lignes de python que je vous avez indiquées pour réaliser des graphiques.
      
    </p>

    <h4>Distinguer une classe séparable</h3>

    <p>

      ...

      <br/>

      Compter et afficher le nombre d'exemples dont la classe est mal prédite.

      <br/>
      
      Tester différentes valeur de &epsilon; (par exemple 10<sup>-2</sup>, 10<sup>-4</sup>, 10<sup>-6</sup>)

    </p>

    <h4>Cas où les classes ne sont pas linéairement séparables</h3>

    <p>

    </p>

    
    <h2>Fonction d'activation tangente hyperbolique</h2>

    <p>

      Refaire tout ce que vous avez fait pour la fonction d'activation tangente hyperbolique.
      
    </p>

    <ul>
      <li>Il faut bien sûr changer le calcul de l'activation du perceptron. Pour utiliser la fonction <kbd>tanh()</kbd>, on doit auparavant effectuer l'instruction <kbd>from math import tanh</kbd>.
	<br/>
	Quand on calcule la sortie s du perceptron, on doit donc utiliser la tangente hyperbolique.
      </li>
      <li>Il faut modifier la correction des poids. Le terme s (1 - s) correspond à la fonction logistique. Pour la tangente hyperbolique, il faut le remplacer par (1 - s * s).</li>
      <li>Avec ces deux modifications, votre programme devrait déjà fonctionner.</li>
      <li>Avec la tangente hyperbolique, la valeur de &epsilon; peut être bien plus grande. 0,1 suffit, ce qui permet de réaliser beaucoup moins d'itérations, donc que le calcul des poids est beaucoup plus rapide. Comparez le résultat en utilisant différentes valeurs de &epsilon; comme vous l'avez fait plus haut pour la fonction d'activation logistique.</li>
    </ul>
  
    <h2>Pour finir</h2>

    <p>

      Le source de votre programme doit respecter les points suivants&nbsp;:
      
    </p>
    
    <ul>
      <li>il doit commencer par un commentaire indiquant son titre, son objet, ses auteurs, la date de réalisation.</li>
      <li>Chaque fonction doit commencer par un commentaire indiquant au minimum ce que fait la fonction, le sens des paramètres, les pré-conditions et ce que la fonction retourne.</li>
      <li>Le type des paramètres des fonctions doit être indiqué, ainsi que le type de la valeur retournée.</li>
    </ul>
    
    <p>
      
      Pour finir, vous m'envoyez votre/vos script(s) par email, en mettant votre binôme en cc.
      
    </p>
    
    </div>
    
    </body>
</html>
