<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Classification supervisée (éléments de correction)</title>
    <link href="https://philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all">
    <!--link href="file:///home/ppreux/philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all"-->
    <link rel="shortcut icon" type="image/x-icon" 
	  href="https://philippe-preux.github.io/img/site.ico">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
      .aligncenter {
	  text-align: center;
      }
      span.petit {
	  font-size: 8px;
      }
    </style>
  </head>
  
  <body>
    <div class="tpR">

      <h1>Classification supervisée (éléments de correction)</h1>
      
      <p>
	
	Dans ce TP, on va aborder la classification supervisée en la mettant en &oelig;uvre sur le jeu de données <kbd>olives</kbd>. Les notions essentielles de classification supervisée ont été vues en L2. Il s'agît donc ici de rappel et surtout de mise en pratique. Si nécessaire, on pourra consulter mes <a href="https://philippe-preux.github.io/Documents/notes-de-cours-de-fouille-de-donnees.pdf">notes de cours de fouille de données</a> pour une présentation de la classification supervisée.

	<br>

	Les 2 TPs précédents (<a href="../df">tableaux de données</a> et <a href="../graphiques">graphiques</a>) doivent impérativement avoir été faits.
	
	<br>
	<br>
	
	À l'issue de ce TP, vous m'envoyez par email un compte-rendu (format <kbd>odt</kbd> ou <kbd>pdf</kbd>) indiquant la réponse aux questions qui sont posées. Vous m'envoyez également un fichier python réalisant toutes les manipulations de ce TP&nbsp;: je dois pouvoir exécuter ce fichier en tapant <kbd>python3 nom-de-votre-fichier.py</kbd> et reproduire vos résultats. Cette exécution ne doit pas provoquer d'erreur de python. Remarque&nbsp;: un <i>notebook</i> ne convient pas.
    
      </p>

      <h2>Introduction</h2>
    
      <p>

	Les olives du jeu de données proviennent chacune d'une région particulière d'Italie&nbsp;: sud, Sardaigne, nord. Celles-ci sont numérotées et la valeur associée à chaque olive est dans l'attribut 1 dénommé <kbd>region</kbd>. Chaque région est découpée en sous-régions&nbsp;; cette sous-région est dans les attributs 0 et 2&nbsp;; l'attribut 2 est juste le numéro de la sous-région dont le nom est donné par l'attribut 0. La carte ci-dessous indique ces régions et certaines sous-régions.
    
      </p>

      <p class="aligncenter">
	<img src="./olives-italie.png" width="400"
	     alt="carte des zones géographiques d'origine des olvies du jeu de données">
	<!--figcaption--><span class="petit">(Cette figure est issue du livre sur <a href="http://ggobi.org/book.html">ggobi</a>.)</span><!--/figcaption-->
      </p>
      
      <p>

	Chaque olive étant par ailleurs caractérisée par sa teneur en certains acides, la question que nous étudions dans ce TP est&nbsp;: à partir de cette composition chimique, peut-on déterminer la provenance géographique de l'olive&nbsp;?

	<br>

	Si on arrive à déterminer la provenance à partir de la composition chimique de l'olive, on peut garantir que la provenance indiquée est la bonne et pourquoi pas, détecter ainsi des tentatives de fraudes si ce n'est pas le cas.

	<br>
	<br>
	
	On va pratiquer en deux phases. Durant la première, on va explorer visuellement le jeu de données&nbsp;: la réponse à la question posée est-elle visible sur un ou des graphiques&nbsp;? Durant la seconde, on va utiliser un algorithme d'apprentissage automatique pour essayer de répondre à la question. Les deux approches ne sont pas exclusives, bien au contraire&nbsp;: la première guide le choix d'une méthode à appliquer lors de la seconde.
    
      </p>

      <div class="correction">
	On commence par charger le jeu de données et faire les petits ajustements nécessaires&nbsp;:
	<br>
	<pre>import pandas as pd

olives = pd.read_csv ("/home/ppreux/philippe-preux.github.io/ensg/miashs/datasets/olives.csv", header = 0)
olives.rename (columns = {"Unnamed: 0": "Area Name"}, inplace = True)
olives ["Area Name"] = olives ["Area Name"]. astype ("category")
olives ["region"] = olives ["region"]. astype ("category")
olives ["area"] = olives ["area"]. astype ("category")</pre>
	<br>
	En anticipant ce qui est expliqué plus loin dans le TP, on initialise le générateur de nombres pseduo-aléatoires. C'est à faire en début de programme.
	<br>
	<pre>import numpy as np
graine = int ("ScienceDesDonnees", base=36)%2**31
rs = np.random.RandomState (graine)</pre>
      </div>

      <h2>Premiers pas&nbsp;: approche graphique (exploration visuelle des données)</h2>

      <p>

	Face à un jeu de données, la première chose à faire et de l'explorer visuellement. Dans le cas où on souhaite prédire la valeur d'un attribut, on se pose la question&nbsp;: la réponse à la question qui est posée saute-t-elle aux yeux&nbsp;?

	<br>

	Donc, on commence par faire des graphiques très simples pour voir s'il est possible de prédire la région de provenance de l'olive.
	
	On commence par la région car il y a 3 régions (attribut <kbd>region</kbd>) qui se découpent en 8 zones (attributs et <kbd>Area Name</kbd> et <kbd>area</kbd>). Il est donc probablement plus facile de déterminer la région que la zone.

	<br>

	Cette exploration visuelle permet également d'orienter le choix d'un modèle pour réaliser la tâche de prédiction&nbsp;: si on voit des relations simples, on sait que des modèles simples pourront réaliser les prédictions voulues.
    
      </p>
  
      <h3>Visualisation univariée&nbsp;: répartition des valeurs de chaque attribut en fonction de sa classe</h3>
  
      <p>

	Par graphique très simple, on entend la visualisation de la répartition de la valeur d'un attribut (= univarié) en fonction de sa classe. Pour chaque acide, on réalise un graphique comme celui-ci pour l'attribut <kbd>palmitic</kbd>&nbsp;:

      </p>

      <p class="aligncenter">
	<img src="palmitic-par-classe.png" width="500"
	     alt="Taux d'acide palmatique dans les olives du jeu de données">
      </p>
      
      <ul>
	<li>En ordonnées, c'est le numéro de la donnée (la ligne dans le jeu de données)&nbsp;;</li>
	<li>en abscisses, la valeur de l'attribut <kbd>palmitic</kbd>&nbsp;;</li>
	<li>la couleur indique la région&nbsp;:
	  <ol>
	    <li>sud de l'italie en bleu&nbsp;;</li>
	    <li>Sardaigne en rose&nbsp;;</li>
	    <li>nord de l'italie en jaune.</li>
	</ol></li>
      </ul>
      
      <p>
	
	D'un coup d'&oelig;il, on voit que cet attribut ne permet pas de distinguer les olives des 3 classes. Quand on considère une valeur de l'acide palmitique supérieure à 1400, on voit que l'on peut en déduire que l'olive provient de la zone 1&nbsp;: il n'y a que des points bleus pour ces abscisses&nbsp;: tout va bien. Par contre, si cette valeur est comprise entre 1000 et 1200, les 3 classes sont possibles&nbsp;: pour ces abscisses, on voit des points des 3 couleurs. Donc, si la teneur en acide palmitique est 1100, on ne peut pas déterminer la zone d'origine de l'olive.

	<br>

	En conclusion, l'attribut <kbd>palmitic</kbd> ne permet pas de déterminer la région d'origine de l'olive.

	<br>
	<br>
	
	<b>À faire&nbsp;:</b> réalisez ce graphique pour chacun des 8 acides et concluez (vérifiez que vous obtenez bien le même graphique que moi pour l'acide palmitique). Y a-t-il un, ou des attributs, qui permet de déterminer la région d'origine&nbsp;? ou qui peut aider&nbsp;?

	<br>

	Remarque&nbsp;: pour réaliser ce graphique, j'ai ajouté une colonne <kbd>numero</kbd> au tableau de données <kbd>olives</kbd>. Cette colonne contient tout simplement le numéro de la donnée.

      </p>

      <div class="correction">

	On fait une boucle pour obtenir les graphiques&nbsp;:
	
	<br>
	
	<pre>import matplotlib.pyplot as plt
olives ["numero"] = range (olives.shape [0])
acides = list(olives) [3:11]
for acide in acides:
    olives.plot.scatter (x = acide, y = "numero", title = "Scatter plot", c = "region", colormap = "plasma")

plt.show ()</pre>
      </div>
   
      <p>
	
	<b>À faire&nbsp;:</b> sans dévoiler la solution, vous devez trouver un attribut qui sépare l'une des classes des deux autres. Pour celui-ci, vous obtenez un graphique qui ressemble à celui-ci&nbsp;:

      </p>

      <p class="aligncenter">
	<img src="allure-generale.png" width="500" alt="Allure générale du graphique recherché.">
      </p>
  
      <p>

	Ce graphique montre que la classe 1 (points bleus) est facilement identifiée grâce à cet attribut.

      </p>

      <div class="correction">
	C'est l'attribut eiconsenoic qui sépare les exemples du Sud des deux autres classes.
      </div>
      
      <p>
    
	Quand vous l'avez trouvé, vous pouvez vous concentrer sur les 2 classes qui sont encore mélangées (jaune et rouge) et recommencer le même raisonnement en vous occupant uniquement des données de ces deux classes. Vous devez trouver un attribut qui sépare bien ces 2 classes restantes.

	<br>

	Quels sont ces deux attributs et comment pouvez-vous déterminer la classe à partir de ces deux attributs&nbsp;?
    
      </p>

      <div class="correction">
	<br>
	on ne s'intéresse qu'aux exemples de classe 2 et 3.
	<br>
	<pre>acides = list(olives) [3:11]
for acide in acides:
    olives [olives.region != 1].plot.scatter (x = acide, y = "numero", title = "Scatter plot régions 2 et 3", c = "region", colormap = "plasma")

plt.show ()</pre>
	<br>	
	Ce qui donne les 8 graphiques suivant&nbsp;:
	<br>
	<img src="./arachidic.png" width="300" alt="">
	<img src="./eicosenoic.png" width="300" alt="">
	<img src="./linoleic.png" width="300" alt="">
	<img src="./linolenic.png" width="300" alt="">
	<br>	
	<img src="./oleic.png" width="300" alt="">
	<img src="./palmitic.png" width="300" alt="">
	<img src="./palmitoleic.png" width="300" alt="">
	<img src="./stearic.png" width="300" alt="">
	<br>
	Ce n'est pas évident de le voir, mais les deux classes peuvent être séparées avec l'acide linoleic. On peut le vérifier en comparant
	<br>
	<pre>>>> np.min (olives.linoleic [olives.region == 2])
1057
>>> np.max (olives.linoleic [olives.region == 3])
1050</pre>
	Il y a bien un écart entre les deux classes, petit, mais l'algorithme d'induction d'un arbre de décision le détecte sans difficulté.
      </div>
      
      <h3>Visualisation bivariée</h3>

      <p>

	«&nbsp;Bivariée&nbsp;» signifie que l'on considère deux attributs.
	L'idée est ici la même que précédemment, mais au lieu de chercher une relation entre un attribut et la classe, on cherche une relation entre un couple d'attributs et la classe.

	<br>

	Reprenons le schéma réalisé à la fin du TP précédent&nbsp;:
    
      </p>

      <p class="aligncenter">
	<img src="../graphiques/olives-palmitic-vs-oleic-against-region.png" width="500" alt="Les olives du jeu de données dans le plan des attributs oleic/palmitic.">
      </p>
  
      <p>
	
	On voit que ces deux attributs ne permettent pas de déterminer la classe de manière simple&nbsp;: les points des 3 couleurs sont mélangés.

	<br>

	On peut quand même voir que pour une valeur de l'acide oléique inférieure à (environ) 7200, l'acide palmitique permet à peu près de bien prédire la classe 1 ou 3. Cela ne répond pas à notre question, mais c'est un élément d'information.

	<br>
	<br>

	Je pourrais vous demander de chercher s'il existe une paire d'attributs qui permettent de prédire la région d'origine des olives mais je sais que cette recherche sera vaine et qu'elle vous prendra du temps. Donc vous pouvez passer à la suite, ou quand même vérifier qu'il n'y a rien à voir de simple sur aucun de ces graphiques.
    
      </p>

      <h2>Approche automatique</h2>

      <p>

	Il arrive que l'approche visuelle ne permette pas de voir quelque chose (c'est rare). Quoiqu'il en soit, en complément de l'exploration visuelle, nous allons essayer de prédire la région d'origine de l'olive à l'aide de méthodes qui ont pour objectif d'apprendre un modèle réalisant ce type de prédiction.

	<br>
	<br>

	Face à un jeu de données de petite taille comme celui-ci (quelques centaines de lignes, une dizaine de colonnes, quelques classes), on commence par essayer une méthode qui généralement donne de très bons résultats, les arbres de décision. L'induction d'un arbre de décision est très souvent une méthode très efficace, très peu coûteuse en temps de calcul, qui donne de très bonnes performances pour la prédiction de la classe.

	<br>
	<br>
    
	Pour cela, on va utiliser la bibliotèque <kbd>scikit_learn</kbd>. Pour pouvoir créer des arbres de décision, on fera&nbsp;: <kbd>from sklearn import tree</kbd>.

	<br>

	La documentation est <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree">là</a>.
    
      </p>

      <h3>Induction d'un arbre de décision</h3>

      <p>

	Pour induire un modèle, on fait comme suit&nbsp;: le jeu de données est découpé en deux parties, l'une utilisée pour induire le modèle, la seconde pour estimer la probabilité qu'il commette une erreur lors d'une prédiction.

	<br>

	La première partie constitue les données d'entraînement, la seconde les données de test.

	<br>

	Il est classique d'utiliser 80% des données disponibles comme données d'entraînement, les 20% restant constituant les données de test.

	<br>

	La répartition entre les deux parties est faite aléatoirement. Il est important de vérifier que les données sont stratifiées, c'est-à-dire que la proportion des données de chaque classe est à peu près la même dans les deux parties.

	<br>
	<br>

	Pour découper le jeu de données en ces deux parties, on utilise la fonction <code>train_test_split ()</code> de la bibliothèque <code>sklearn.model_selection</code>.

	<br>

	On fera donc&nbsp;: <code>from sklearn.model_selection import train_test_split</code>.

	<br>

	et ensuite, pour partitionner le jeu d'exemples en 20% pour le jeu de test et 80% pour le jeu d'entraînement&nbsp;:
      
      </p>

      <pre>
olivesX_train, olivesX_test, olivesY_train, olivesY_test = train_test_split (olives.iloc [:,3:11], olives.region, test_size = .2, random_state = 123)</pre>

      <p>

	Suite à cet appel, on obtient 4 objets&nbsp;:
      
      </p>

      <ul>
	<li><code>olivesX_train</code> est un tableau de données qui contient 80% des olives. Seuls les 8 attributs numérotés 3 à 10 ont été sélectionnés, c'est-à-dire les attributs indiquant la composition chimique des olives.</li>
	<li><code>olivesX_test</code> est un tableau de données qui contient les 20% restants des olives.</li>
	<li><code>olivesY_train</code> est un tableau de données comprenant une seule colonne (<code>region</code>) qui indique la classe de chaque élément de <code>olivesX_train</code>.</li>
	<li><code>olivesY_test</code> est un tableau de données comprenant une seule colonne (<code>region</code>) qui indique la classe de chaque élément de <code>olivesX_test</code>.</li>
      </ul>
    
  <p>

    <code>olivesX_train</code> et <code>olivesY_train</code> constituent le jeu de données d'entraînement avec lequel on construit un modèle de prédiction de la classe.

    <br>
    
    <code>olivesX_test</code> et <code>olivesY_test</code> constituent le jeu de données de test avec lequel on mesure la qualité du modèle (est-ce que le modèle prédit bien la classe d'une donnée&nbsp;? ou dit autement, quelle est la probabilité que le modèle fasse une prédiction erronnée).
    
    <br>
    <br>
	
    Nous pouvons maintenant induire l'arbre de décision. Il faut tout d'abord importer la fonction qui induit des arbres de décision avec <code>from sklearn import tree</code>, puis l'induction de l'arbre se fait comme quit&nbsp;:

    </p>
    
    <pre>arbre = tree.DecisionTreeClassifier()
arbre = arbre.fit (olivesX_train, olivesY_train)</pre>

    <p>

    La première ligne crée un objet arbre de décision et l'affecte à la variable dénommée <code>arbre</code>. La seconde induit l'arbre en utilisant les données et étiquettes du jeu d'entraînement.
    
    <br>
    <br>

    <b>À faire&nbsp;:</b>

    </p>

  <ol>
    <li>créer les 4 objets <code>olivesX_train</code>, <code>olivesX_test</code>, <code>olivesY_train</code> et <code>olivesY_test</code>.
      <br>
      <div class="correction">
	Vu plus haut.
      </div>
    </li>
    <li>Vérifier que la proportion des données de chacune des 3 classes est à peu près la même dans le jeu de données initial, dans le jeu de données d'entraînement et le jeu de données de test.
      <br>
      <div class="correction">
	On calcule la proportion des exemples de chacune des trois classes dans le jeu d'entraînement puis dans le jeu de test&nbsp;:
	<pre>>>> olivesY_train.value_counts()/olivesX_train.shape[0]
1    0.586433
3    0.253829
2    0.159737
Name: region, dtype: float64
>>> olivesY_test.value_counts()/olivesY_test.shape[0]
1    0.478261
3    0.304348
2    0.217391
Name: region, dtype: float64</pre>
      </div>
      <br>
      et on constate que les proportions sont à peu près les mêmes.
    </li>
    <li>Induire un arbre de décision à partir de <kbd>olivesX_train</kbd> et <code>olivesY_train</code>. Il y a beaucoup de paramètres qui peuvent être réglés mais nous nous en tiendrons à leur valeur par défaut dans un premier temps (<i>cf.</i> ci-dessus).
      <br>
      <div class="correction">
	Vu plus haut.
      </div>
    </li>
  </ol>
  
      <p>

	Une fois un arbre de décision induit, on peut l'utiliser pour prédire la classe de données en utilisant la méthode <code>predict ()</code>. Cette méthode prend simplement un tableau de données. Par exemple, <code>arbre.predict (olivesX_train)</code> calcule la classe prédite par l'<code>arbre</code> sur les données contenues dans le tableau de données <code>olivesX_train</code>.

      </p>
      
  <h3>Diagnostic de l'arbre de décision</h3>

  <p>

    Avant même de regarder à quoi l'arbre ressemble, il est important de commencer par déterminer si cet arbre est capable de prédire la classe de manière précise. On va donc estimer la probabilité qu'il commette une erreur lorsqu'il prédit la classe d'une donnée. Pour cela, on&nbsp;:

  </p>

  <ul>
    <li>utilise les données de test que l'on a mises de côté dans <kbd>olivesX_test</kbd> et <kbd>olivesY_test</kbd>,</li>
    <li>on utilise l'arbre pour prédire la classe des données contenues dans <code>olivesX_test</code>,</li>
    <li>on compare la classe prédite avec la classe de la donnée qui est dans <code>olivesY_test</code>.</li>
    <li>On divise le nombre d'erreurs de prédiction par le nombre de données de test&nbsp;: cela nous fournit une estimation de la probabilité d'erreur.</li>
  </ul>
  
  <p>

    <b>À faire&nbsp;:</b> faites ce qui vient d'être expliqué. Quelle est la valeur de cette estimation&nbsp;?
  </p>
  
  <div class="correction">
    <pre>sum (arbre.predict (olivesX_test) == olivesY_test) / X_test.shape [0]</pre>
  </div>

  <p>
	
    Il est intéressant de mesurer ce taux d'erreur pour chaque classe.

    <br>

    <b>À faire&nbsp;:</b> mesurer le taux d'erreur pour chaque classe. Les 3 classes sont-elles toutes les 3 prédites correctement avec la même probabilité&nbsp;?
    
  </p>

  <div class="correction">
    <pre>for cl in olivesY_test.unique():
    filtre = olivesY_test == cl
    print ("Taux de succès pour la prédiction de la classe {:2.f} : {:2.f}.".format (cl, sum (arbre.predict (olivesX_test.loc [filtre,:]) == olivesY_test [filtre]) / sum (filtre)))</pre>
  </div>

  <h3>Interprétation d'un arbre de décision</h3>

  <p>

    On peut obtenir une visualisation de l'arbre de décision en faisant par exemple&nbsp;:
    
  </p>

<pre>import matplotlib.pyplot as plt
tree.plot_tree (arbre)
plt.show ()
</pre>

  <p>
    
    qui ouvre une fenêtre avec le graphique suivant&nbsp;:

  </p>

  <p class="aligncenter">
    <img src="arbre-region.png" width="500" alt="Arbre de décision">
  </p>
  
  <p>
    
    <b>À faire&nbsp;:</b> réalisez ce graphique et le comprendre. En particulier, comprendre ce qui est affiché dans chaque n&oelig;ud.

  </p>


  <div class="correction">
    Dans chaque n&oelig;ud, on trouve de haut en bas, par exemple pour le n&oelig;ud racine&nbsp;:
    <ul>
      <li><code>X [7] &lt; 6.5</code>&nbsp;: le test réalisé dans le n&oelig;ud.</li>
      <li><code>gini = 0.566</code>&nbsp;: impureté de l'ensemble d'exemples utilisé pour créer ce n&oelig;ud. On applique la formule \( \sum_{c \in classe} p_c (1 - p_c) \), soit <code>sum (olivesY_train.value_counts()/olivesY_train.shape[0] * (1 - olivesY_train.value_counts()/olivesY_train.shape[0]))</code></li>
      <li><code>samples = 457</code>&nbsp;: le cardinal de l'ensemble d'exemples utilisés pour construire ce n&oelig;ud. Pour le n&oelig;ud racine, c'est <code>olivesX_train. shape [0]</code>.</li>
      <li><code>value = [268, 73, 116]</code>&nbsp;: <code>olivesY_train.value_counts()</code>.</li>
    </ul>
  </div>
  
  <p>

    Les tests réalisés à chaque n&oelig;ud sont difficiles à comprendre. Pour afficher le nom des attributs, on ajoutera <kbd>feature_names = list (olives_train)</kbd> dans l'appel de la méthode <kbd>plot_tree()</kbd>. Et on obtient&nbsp;:
    
  </p>

  <p class="aligncenter">
    <img src="arbre-region-avec-le-nom-des-attributs.png" width="500" alt="Arbre de décision avec le nom des attributs">
  </p>
  
  <p>

    En consultant <a href="https://scikit-learn.org/stable/modules/tree.html#tree">la documentation</a>, on peut avoir une représentation plus jolie et informative avec la classe prédite qui est indiquée dans chaque feuille, comme celle-ci&nbsp;:

  </p>
  
  <p class="aligncenter">
    <img src="arbre-region-plus-joli.png" width="500" alt="Joli arbre de décision">
  </p>
  
  <p>

    <b>Faites-le.</b>

  </p>
  
  <div class="correction">
    <pre>tree.plot_tree (arbre, feature_names = list (olivesX_train), class_names = ["Sud", "Sardaigne", "Nord"], filled = True)
plt.show ()</pre>
  </div>
  
      <p>

	Un arbre de décision peut facilement être transformé en un ensemble de règles de décision. Ici l'arbre est très petit, c'est facile.

	<br>
	<br>
	
	<b>À faire&nbsp;:</b> quelles sont ces règles&nbsp;? Interprétez graphiquement ces règles. Retrouvez-vous une observation faite précédemment&nbsp;?
	
      </p>
      
      <div class="correction">
	<p>
	  Si l'attribut <code>eicosenoic</code> est &gt; 6,5 alors la classe est Sud.
	  <br>
	  Sinon, si l'attribut <code>linoleic</code> est &le; 1048,8, alors sa classe est Nord, sinon c'est Sardaigne.
	</p>
      </div>
  
      <h3>Test de l'arbre de décision</h3>

  <p>

    Nous avons construit un arbre de décision qui donne de très bons résultats. Est-ce juste de la chance ou est-ce que décidément, cette tâche se résout facilement à l'aide d'un arbre de décision&nbsp;?

    <br>
    <br>

    Pour apporter des éléments de réponse à cette question, on refait plusieurs fois la construction de l'arbre de décision en découpant le jeu de données aléatoirement à chaque fois. Par exemple, on peut refaire toute cette procédure 30 fois (ou 100, ...). Pour chaque arbre induit, on estime sa probabilité d'erreur de prédiction que l'on stocke. Une fois les 30 (ou 100, ...) constructions réalisées, on vérifie que la probabilité d'erreur varie, peu, un peu, beaucoup, ... Si elle varie peu, c'est très bon signe&nbsp;: tous les arbres induits ont à peu près la même précision, qui est très bonne pour la prédiction de la région d'origine de l'olive.

    <br>
    <br>

    <b>À faire&nbsp;:</b> effectuer ce qui vient d'être expliqué. Que pensez-vous du résultat&nbsp;?

  <div class="correction">
    <pre>taux_de_succès = []
for i in range (100):
    olivesX_train, olivesX_test, olivesY_train, olivesY_test = train_test_split (olives.iloc [:,3:11], olives.region, test_size = .2, random_state = i)
    arbre = tree.DecisionTreeClassifier()
    arbre = arbre.fit (olivesX_train, olivesY_train)
    taux_de_succès.append (sum (arbre.predict (olivesX_test) == olivesY_test) / olivesX_test.shape [0])

print ("Taux de succès moyen et écart-type : {:.2f}, {:.2f}".format (np.mean(taux_de_succès), np.std (taux_de_succès)))</pre>
    
    ce qui me donne <code>1.00 0.00</code>.
  </div>

  <p>
    
    La manière traditionnelle d'effectuer cela se nomme une <em>validation croisée</em>. Une validation croisée consiste à&nbsp;:

  </p>

  <ol>
    <li>découper le jeu d'exemples en N parties stratifiées,</li>
    <li>pour chacune des parties, induire un arbre en utilisant les N-1 autres parties et mesurer son erreur de prédiction sur la partie non utilisée dans l'entraînement.</li>
    <li>faire la moyenne de ces erreurs.</li>
  </ol>

  <p>

    Il faut importer la fonction par <code>from sklearn.model_selection import cross_val_score</code>. Elle s'utilise ensuite de la manière suivante&nbsp;:

    </p>

    <pre>>>> cross_val_score (arbre, olives.iloc [:, 3:olives.shape[1]], olives.iloc [:,1], cv = 10)
array([0.77586207, 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 0.63157895])</pre>

    <p>

    On a fixé le nombre de parties N à 10 <i>via</i> le paramètre <code>cv</code>. La fonction affiche les 10 taux de succès mesurées sur chacune des 10 parties.
    
    <br>
    
    <b>À faire&nbsp;:</b> effectuer une validation croisée et comparer le résultat (erreur estimée) avec la valeur que vous avez obtenue précédemment.

  </p>


  <div class="correction">
    <pre>taux_de_succès_par_cv = cross_val_score (arbre, olives.iloc [:, 3:olives.shape[1]], olives.iloc [:,1], cv = 10)
print ("Taux de succès moyen et écart-type : {:.2f}, {:.2f}".format (np.mean(taux_de_succès_par_cv), np.std (taux_de_succès_par_cv)))</pre>
    
    ce qui me donne <code>0.94, 0.12</code>. Le taux d'erreur est donc supérieur à l'estimation précédente.
    
  </div>
    
  <h3>Reproductibilité</h3>

  <!--p>
    
    <img src="https://philippe-preux.github.io/img/attention-vector-id866109136.jpg" width="300">

    Le contenu de cette section a changé depuis la séance du 18 octobre.
    Si vous aviez atteint cet partie de l'énoncé, corrigez votre code python.
    
  </p-->
  
  <p>

    Pour construire les jeux de données d'entraînement et de test, nous avons utilisé des nombres générés pseudo-aléatoirement. Si vous effectuez ce qui a été expliqué plus haut pour l'induction d'un arbre deux fois de suite, vous obtiendrez des résultats différents (dans le cas présent, la différence est petite). Il est important de pouvoir reproduire les résultats que vous avez obtenu. Pour cela, il faut que les nombres pseudo-aléatoires qui sont générés soient les mêmes d'une exécution à la suivante. Pour obtenir ce résultat, il faut initialiser la <i>graine</i> du générateur de nombres pseudo-aléatoires.
    <!--
	Ces nombres étant générés dans le paquetage <kbd>numpy</kbd>, il faut initialiser cette graine dès que ce paquetage a été chargé. Pour cela, on exécute l'instruction <kbd>np.random.seed (le-nombre-que-vous-voulez)</kbd> où vous remplacez <kbd>le-nombre-que-vous-voulez</kbd> par le nombre que vous voulez, éventuellement avec beaucoup de chiffres. -->
    On fait ainsi&nbsp;:

  </p>
  
<pre>
graine = int ("ScienceDesDonnees", base=36)%2**31
rs = np.random.RandomState (graine)
</pre>

  <p>
    
    <kbd>graine</kbd> est un entier. La première ligne transforme une chaîne de caractères quelconque en un entier (à la place de ce qui est écrit, vous pouvez écrire tout simplement <kbd>graine = 1234567</kbd> par exemple). Ensuite, on initialise le générateur de nombres pseudo-aléatoires.

    <br>
    
    Puis, lors de l'induction de l'arbre de décision, on passe celui-ci en paramètre&nbsp;:

  </p>
  
<pre>DecisionTreeClassifier (random_state = rs)</pre>

  <p>

    Plus haut, quand on a découpé le jeu de données en jeu d'entraînement et jeu de test, on a spécifié un paramètre <code>rs</code> également qui joue le même rôle pour ce découpage que le paramètre <code>random_state</code> pour l'induction de l'arbre de décision. Pour obtenir le même découpage, il faut que le paramètre ait la même valeur (et que le jeu de données à partitionner soit identique).

    <br>
    <br>
    
    <b>À faire&nbsp;:</b> effectuer l'initialisation de cette graine et refaites toute la procédure d'induction d'arbre. Estimer sa probabiité d'erreur. Si vous effectuez cela plusieurs fois, vous devez obtenir exactement le même résultat à chaque fois.
    
  </p>

  <h2>Prédiction de l'attribut <kbd>area</kbd></h2>
  
<p>
  
  Chaque région est décomposée en un ensemble d'aires (attribut <kbd>area</kbd>). On essaie maintenant de prédire l'aire, il y en a 8.

    <br>
    <br>

    <b>À faire&nbsp;:</b>

</p>

<ul>
  <li>Refaites le même travail pour prédire l'attribut <kbd>area</kbd>.</li>
  <li>Arrive-t-on à bien prédire toutes les classes&nbsp;? Aussi bien que la région&nbsp;?
    <br>
    Pour répondre à cette question, vous calculez l'erreur de test pour l'ensemble des exemples mais aussi, vous calculez cette erreur pour les exemples de chacune des 3 et 8 classes respectivement.
    <br>
    Qu'en pensez-vous&nbsp;?</li>
</ul>

<div class="correction">

  Pour la région, pour chaque classe, le taux de succès de l'arbre induit précédemment est estimé par&nbsp;:

  <br>

<pre>for classe in list (olivesY_test.unique()):
    print ("Taux de succès pour la prédiction de la classe {} : {:.2f}".format (classe, sum (arbre.predict (olivesX_test.loc [olivesY_test == classe]) == classe) / sum (olivesY_test == classe)))</pre>

<br>

ce qui donne 1 pour les 3 classes.

<br>

Pour la zone, on refait la procédure et on obtient&nbsp;:

<pre>areaX_train, areaX_test, areaY_train, areaY_test = train_test_split (olives.iloc [:,3:11], olives.area, test_size = .2, random_state = 123)
arbreArea = tree.DecisionTreeClassifier()
arbreArea = arbreArea.fit (areaX_train, areaY_train)
for classe in np.sort (list (areaY_test.unique())):
    print ("{} {:.2f}".format (classe, sum (arbreArea.predict (areaX_test.loc [areaY_test == classe]) == classe) / sum (areaY_test == classe)))</pre>
<br>

ce qui me donne&nbsp;:

<br>

<pre>1 0.80
2 0.50
3 0.97
4 0.40
5 0.95
6 1.00
7 0.69
8 0.92
9 0.90
</pre>

<br>

C'est donc beaucoup moins bien, notamment pour les zones 2 et 4 qui sont mal prédites. On conclut que la prédiction de la zone est plus difficile que la prédiction de la région. 

</div>

  <h2>Retour sur la prédiction de l'attribut <kbd>region</kbd></h2>

<p>

  L'arbre de décision construit plus haut commet parfois des erreurs. Nous allons voir une manière de réduire le risque d'erreur.

  <br>

  C'est une méthode très générale qu'il faut absolument connaître et utiliser lorsqu'on utilise des arbres de décision.

  <br>

  Nous allons procéder visuellement car cette manière de faire ne s'automatise pas facilement. Alors que parfois, comme on l'a déjà dit, il y a des choses qui sautent aux yeux.

  <br>
  <br>

  L'arbre obtenu prédit parfaitement les olives du Sud de l'Italie&nbsp;; on l'avait déjà vu. Par contre, il ne sépare pas parfaitement les deux autres régions, Nord et Sardaigne. On va donc se concentrer sur les olives de ces deux régions.

  <br>

  Pour cela et pour se simplifier la vie, on peut créer un objet <code>olivesPasDuSud</code> à l'aide d'un filtre logique&nbsp;: <code>lesOlivesPasDuSud = olives.loc [:,"region"] != 1</code>.

  <br>
  
  Ensuite, on fait des <i>scatter plots</i> de ces olives pour chaque paire d'attributs et en utilisant une couleur indiquant la région. On regarde ces graphiques et on essaie d'en identifier où les 2 olives des deux régions sont séparées. Rappelons-nous qu'un arbre de décision (comme ceux construits par l'algorithme disponible dans <code>scikit-learn</code> que nous utilisons) découpe l'espace de données avec des droites parallèles aux axes, ce qui correspond à des tests du type attribut &le; valeur. Essayons de trouver une paire d'attributs permettant de séparer les deux classes par une droite.

  <br>

  Avec 8 attributs, nous obtenons 8x7/2 graphiques&nbsp;:

  <br>

  <img src="arachidic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="linoleic-vs-arachidic.png" width="300" alt="fig">
  <img src="linoleic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="linoleic-vs-linolenic.png" width="300" alt="fig">
  <img src="linolenic-vs-arachidic.png" width="300" alt="fig">
  <img src="linolenic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="oleic-vs-arachidic.png" width="300" alt="fig">
  
  <img src="oleic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="oleic-vs-linoleic.png" width="300" alt="fig">
  <img src="oleic-vs-linolenic.png" width="300" alt="fig">
  <img src="palmitic-vs-arachidic.png" width="300" alt="fig">
  <img src="palmitic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="palmitic-vs-linoleic.png" width="300" alt="fig">
  <img src="palmitic-vs-linolenic.png" width="300" alt="fig">
  
  <img src="palmitic-vs-oleic.png" width="300" alt="fig">
  <img src="palmitic-vs-palmitoleic.png" width="300" alt="fig">
  <img src="palmitic-vs-stearic.png" width="300" alt="fig">
  <img src="palmitoleic-vs-arachidic.png" width="300" alt="fig">
  <img src="palmitoleic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="palmitoleic-vs-linoleic.png" width="300" alt="fig">
  <img src="palmitoleic-vs-linolenic.png" width="300" alt="fig">
  
  <img src="palmitoleic-vs-oleic.png" width="300" alt="fig">
  <img src="palmitoleic-vs-stearic.png" width="300" alt="fig">
  <img src="stearic-vs-arachidic.png" width="300" alt="fig">
  <img src="stearic-vs-eicosenoic.png" width="300" alt="fig">
  <img src="stearic-vs-linoleic.png" width="300" alt="fig">
  <img src="stearic-vs-linolenic.png" width="300" alt="fig">
  <img src="stearic-vs-oleic.png" width="300" alt="fig">

  <br>
  <br>

  <b>À faire&nbsp;:</b> reproduisez ces 28 graphiques.

</p>

<div class="correction">
  Pour réaliser ces 28 graphiques, on fait une boucle. Avant cela, on crée un <i>data frame</i> qui contient uniquement les exemples qui ne sont pas de classe Sud.
  <br>
  <pre>lesOlivesPasDuSud = olives.loc [:,"region"] != 1
# On construit un df qui ne contient que les exemples et les attributs qui nous intéressent
olivesPasDuSud = olives.loc [lesOlivesPasDuSud,]
olivesPasDuSud = olivesPasDuSud.iloc [:,0:11]

attributs = list (olives)
for i in range(3,11):
    for j in range(i+1,11):
        olivesPasDuSud.plot.scatter (x = attributs [i], y = attributs [j], title = "Scatter plot", c = "region", colormap = "tab10")

plt.show ()</pre>
</div>

<p>

  Il faut donc trouver un graphique où les points jaunes et les points violets peuvent être séparés par une droite quelconque. La figure ci-dessous illustre l'idée&nbsp;: les données des deux classes sont illustrées par les tâches colorées et on voit que l'on peut séparer les jaunes des bleus par une droite. N'étant ni horizontale ni verticale, cette droite ne peut pas être trouvée par l'algorithme de <code>scikit-learn</code> qui construit des arbres de décision. Par contre, cette droite nous saute aux yeux, ce qui montre encore une fois que l'être humain est bien supérieur à toutes les machines, même celles dont on prétend qu'elles sont intelligentes ;-)

  <br>

  <img src="combinaison-d-attributs.png" width="400" alt="fig">

  <br>

  Quand on a trouvé une telle paire d'attributs, on détermine l'équation d'une droite qui sépare les deux classes. Comment fait-on&nbsp;? À l'&oelig;il, on détermine deux points par lesquels passent cette droite.

  <br>

  Son équation est de la forme&nbsp;: acideY = a acideX + b, où acideX est l'acide en abscisses, acideY celui en ordonnées, a et b les coefficients de la droite qu'il faut calculer.

  <br>

  Maintenant, on a une règle du genre&nbsp;: si la donnée est en dessous de la droite, alors la classe est bleue, sinon sa classe est jaune. Autrement dit, le signe de acideY - a acideX - b indique la classe.

  <br>

  Dès lors, il suffit d'ajouter un nouvel attribut au jeu de données qui a cette valeur (acideY - a acideX - b) et de construire un arbre de décision avec ce jeu de données augmenté. L'algorithme va utiliser cet attribut pour construire un arbre qui ne fait plus d'erreur, ou du moins, en fait moins. J'obtiens&nbsp;:

  <br>
    
  <img src="arbre_avec_attribut_mystere_sans_test.png" alt="fig">

  <br>

  <b>À faire&nbsp;:</b> Faites tout cela et calculez l'erreur de test du nouvel arbre de décision (j'obtiens 0).

</p>

<div class="correction">
  En regardant tous ces graphiques, on voit que linoleic et arachidic sont séparables par une droite.
  <br>
  On voit qu'une telle droite passe (à peu près) par les points (950, 100) et (1100, 0). On calcule donc l'équation de cette droite&nbsp;: \( arachidic = - 2 linoleic / 3 + 11000 / 15 \).
  <br>
  On vérifie sur un graphique que cette droite sépare bien les deux classes&nbsp;:
  <br>
  <pre>olivesPasDuSud.plot.scatter (x = "linoleic", y = "arachidic", title = "Dans ce plan, une droite sépare les deux classes pour les olives qui ne sont pas de classe Sud", c = "region", colormap = "tab10")
les_x_de_la_droite_séparatrice = np.linspace (950, 1100, 1000)
les_y_de_la_droite_séparatrice = - 2 * les_x_de_la_droite_séparatrice  / 3 + 11000 / 15
plt.plot (les_x_de_la_droite_séparatrice, les_y_de_la_droite_séparatrice, c = "red")
plt.show ()</pre>
  <br>
  Ce qui donne&nbsp;:
  <br>
  <img src="linoleic-vs-arachidic-séparés-par-une-droite.png" width="500" alt="">
  <br>
  On constate que les deux classes sont bien séparées.
  <br>
  On crée un nouveau <i>data frame</i> avec ce nouvel attribut que je dénomme <code>linara</code>&nbsp;:
  <pre>olives2 = olives.iloc [:,:11]
olives2 = olives2.assign (linara = 2 / 3 * olives2.linoleic + olives2.arachidic - 11000 / 15)
olives2X_train, olives2X_test, olives2Y_train, olives2Y_test = train_test_split (olives2.iloc [:,[3:12]], olives2.region, test_size = .2, random_state = 123)

arbre2 = tree.DecisionTreeClassifier (random_state = rs)
arbre2 = arbre2.fit (olives2X_train, olives2Y_train)

print ("Erreur de test : {}".format(sum (arbre2.predict (olives2X_test) != olives2Y_test) / olives2X_test.shape [0]))</pre>
  <br>
  On peut visualiser cet arbre qui utilise bien cet attribut&nbsp;:
  <br>
  <img src="arbre-avec-linara.png" width="500" alt="">
  <br>
  Et on mesure son taux de succès&nbsp;:
  <br>
  <pre>sum (arbre2.predict (olives2X_test) == olives2Y_test) / olives2X_test. shape [0]</pre>
  <br>
  qui vaut 1.
</div>

<p>

  Plus généralement, notre cerveau est capable de repérer des séparatrices bien plus complexes qu'une simple droite&nbsp;: une courbe parabolique, de degré 3, une courbe en zigzag plus généralement, <i>etc.</i>

  <br>

  En guise d'exercice, supposons qu'il n'y ait pas de paire d'attributs séparant les jaunes des bleus (les olives du Nord de celles de Sardaigne).

  <br>
  <br>

  <b>À faire&nbsp;:</b>
  
</p>

<ol>
  <li>repérez une paire d'attributs qui semblent séparer les deux classes par une courbe du 2<sup>nd</sup> degré.</li>
  <li>Une courbe du 2<sup>nd</sup> degré possède 3 coefficients. Cela signifie que nous avons 3 inconnues à déterminer, donc il nous faut 3 points pour les déterminer. À l'&oelig;il, déterminez 3 points par lesquels passent cette courbe du 2<sup>nd</sup> degré.</li>
  <li>Posez le problème mathématique à résoudre pour trouver ces 3 inconnues à partir des coordonnées de ces 3 points.</li>
  <li>Le résoudre.</li>
  <li>En déduire un attribut à ajouter au jeu de données et l'ajouter.</li>
  <li>Construire l'arbre de décision avec ce nouveau jeu de données augmenté (n'utilisez pas l'attribut que nous avons précédemment ajouté correspondant à la séparatrice linéaire).</li>
  <li>Calculez l'erreur de test de ce nouvel arbre de décision.</li>
</ol>


<div class="correction">
  En regardant ces 28 graphiques, on repère au moins 3 paires d'attributs qui semblent séparés par une courbe de nature parabolique. En fait, ce sont plutôt les symétriques de ces 3 figures obtenues en échangeant les 2 axes. Ainsi, linolenic (en x) et linoleic (en y) semblent convenir. On repère que cette parabole semble passer à peu près par les points de coordonnées (10, 1200), (30, 900) et (70, 1200). Avec ces 3 points, on calcule donc a, b et c tels que linoleic = a linolenic^2 + b linolenic + c. On trouve a = 0,625, b = -40 et c = 1537,5. On fait le graphique pour vérifier que cette parabole sépare bien les deux classes&nbsp;:
  <br>
  <pre>olivesPasDuSud.plot.scatter (x = "linolenic", y = "linoleic", title = "Scatter plot", c = "region", colormap = "tab10")
les_x_de_la_parabole_séparatrice = np.linspace (0, 70, 1000)
les_y_de_la_parabole_séparatrice = 0.625 * les_x_de_la_parabole_séparatrice * les_x_de_la_parabole_séparatrice - 40 * les_x_de_la_parabole_séparatrice + 1537.5
plt.plot (les_x_de_la_parabole_séparatrice, les_y_de_la_parabole_séparatrice, c = "red")
plt.show ()</pre>
  <br>
  <img src="linolenic-vs-linoleic-séparés-par-une-parabole.png" width="500" alt="">
  <br>
  On construit un nouveau <i>data frame</i> avec cet attribut. On n'utilise pas linoleic ici car on sait que si cet attribut est présent, il va être utilisé. Ici, on veut vérifier que si cet attribut n'est pas présent, le nouvel attribut correspondant à la parabole va être utilisé.
  <br>
  <pre>paralili = 0.625 * olives. linolenic * olives. linolenic - 40 * olives. linolenic + 1537.5 - olives.linoleic
olives3 = olives.loc [:,['Area Name', 'region', 'area', 'palmitic', 'palmitoleic', 'stearic', 'oleic', 'linolenic', 'arachidic', 'eicosenoic']]
olives3 = olives3.assign (paralili = paralili)
olives3X_train, olives3X_test, olives3Y_train, olives3Y_test = train_test_split (olives3.iloc [:,3:12], olives3.region, test_size = .2, random_state = rs)
arbre3 = tree.DecisionTreeClassifier (random_state = rs)
arbre3 = arbre3.fit (olives3X_train, olives3Y_train)
tree.plot_tree (arbre3, feature_names = list (olives3X_train), class_names = ["Sud", "Sardaigne", "Nord"], filled = True)
plt.show ()</pre>
  et voilà&nbsp;:
  <br>
  <img src="arbre-avec-attribut-parabolique.png" width="500" alt="">
</div>



<h3>Autre question</h3>

<p>

  Quand on dessine un arbre de décision, chaque n&oelig;ud et feuille contient une ligne indiquant <code>gini = ...</code>. Rappel&nbsp;: cette valeur dépend de l'ensemble d'entraînement, elle quantifie l'hétérognéité du jeu de exemples&nbsp;: si tous les exemples sont de la même classe, cette valeur est nulle. Elle vaut \( \sum_{c \in Classes} p_c (1 - p_c) \) où \( p_c \) est la proportion d'exemples appartenant à la classe \( c \). Elle se nomme l'«&nbsp;impureté de Gini&nbsp;».

  <br>

  <b>À faire&nbsp;:</b>
  Calculez cette valeur «&nbsp;à la main&nbsp;» et vérifiez que vous obtenez la même valeur.

</p>

<div class="correction">
  <p>
    Pour l'arbre construit plus avec <code>olivesX_train</code> et <code>olivesY_train</code>, on obtient l'impureté de Gini de la manière suivante&nbsp;:
  </p>
  <pre># calcul des proportions des exemples de chaque classe :
p = olivesY_train.value_counts()/olivesY_train.shape[0]
# utilisation de la formule
sum(p * (1-p))</pre>
</div>

<p>

  Pour un problème à 2 classes, quelle est la valeur maximale de l'impureté de Gini&nbsp;? et pour un problème à C classes&nbsp;?

</p>

<div class="correction">
  <p>
    L'impureté est maximale quand les classes sont équi-réparties. S'il y a 2 classes, les proportions vallent 1/2. Dans ce cas, l'impureté vaut \( 2 \times{} 1/2 (1 - 1/2) = 1/2 \)
    <br>
    S'il y a C classes, l'impureté est maximale quand les proportions sont \( 1/C \). Dans ce cas, l'impureté vaut \( C \times{} 1/C (1 - 1/C) = 1-1/C \).
  </p>
</div>



  
<!--  <br>
  <br>

  Plutôt que l'impureté de Gini, on peut utiliser une autre mesure qui se nomme l'«&nbsp;entropie&nbsp;» qui se calcule par  \( - \sum_{c \in Classes} p_c \log{(p_c)} \). Pour l'utiliser, on ajoute l'option <code>criterion="entropy"</code> à la méthode <code>DecisionTreeClassifier ()</code>.

  <br>
  
  <b>À faire&nbsp;:</b> sur le jeu de données olives d'origine, comparez les arbres construits en utilisant l'impureté de Gini avec ceux construits en utilisant l'entropie. Comme pour l'impureté de Gini, vérifiez «&nbsp;à la main&nbsp;» le calcul de l'entropie. Pour un problème à 2 classes, quelle est la valeur maximale de l'entropie&nbsp;? et pour un problème à C classes&nbsp;?
-->

</div>

<!-- Default Statcounter code for on github
https://philippe-preux.github.io -->
<script>
  var sc_project=12923547; 
  var sc_invisible=1; 
  var sc_security="627600d4"; 
</script>
<script src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript>
  <div class="statcounter">
    <a title="Web Analytics" href="https://statcounter.com/" target="_blank">
      <img class="statcounter"
	   src="https://c.statcounter.com/12923547/0/627600d4/1/"
	   alt="Web Analytics"
	   referrerPolicy="no-referrer-when-downgrade"></a>
  </div>
</noscript>
  <!-- End of Statcounter Code -->
  
</body>
</html>
