<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  <!-- hello world -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Classification supervisée, suite</title>
    <link href="https://philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all">
    <!--link href="file:///home/ppreux/philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all"-->
    <link rel="shortcut icon" type="image/x-icon" 
	  href="https://philippe-preux.github.io/img/site.ico">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
      .aligncenter {
	  text-align: center;
      }
      span.petit {
	  font-size: 8px;
      }
    </style>
  </head>

  <body>
    <div class="tpR">

      <h1>Classification supervisée, suite</h1>

      <p>

	Après l'introduction aux arbres de décision réalisée dans le TP précédent, nous allons poursuivre sur ce thème. On va commencer par étudier comment améliorer la performance des arbres de décision induits sur un jeu de données. Ensuite, on verra comment traiter les attributs nominaux.

	<br>
	<br>
	
	À l'issue de ce TP, vous m'envoyez par email un compte-rendu (format <kbd>odt</kbd> ou <kbd>pdf</kbd>) indiquant la réponse aux questions qui sont posées. Vous m'envoyez également un fichier python réalisant toutes les manipulations de ce TP&nbsp;: je dois pouvoir exécuter ce fichier en tapant <kbd>python3 nom-de-votre-fichier.py</kbd> et reproduire vos résultats. Cette exécution ne doit pas provoquer d'erreur de python. Remarque&nbsp;: un <i>notebook</i> ne convient pas.

      </p>

      <h2>Introduction</h2>

      <p>

	On s'intéresse à un jeu de données concernant le diabète. Au début du TP, nous allons utiliser le jeu de données disponible à cet url <code>https://philippe-preux.github.io/ensg/miashs/datasets/pima-made-easy.csv</code>. Comme son nom l'indique, c'est un jeu de données classiques (pima) que j'ai simplifié.

	<br>
	<br>

	Il y a 9 attributs&nbsp;: 8 sont quantitatifs et le dernier est la classe&nbsp;: patient diabétique (<code>pos</code>) ou pas (<code>neg</code>). Les 8 autres attributs contiennent l'information suivante&nbsp;:

      </p>

      <ul>
	<li><code>pregnant</code>&nbsp;: nombre de grossesses,</li>
	<li><code>glucose</code>&nbsp;: concentration de glucose dans le plasma sanguin 2 heures après un test oral de tolérance au glucose,</li>
	<li><code>pressure</code>&nbsp;: pression sanguine diastolique,</li>
	<li><code>triceps</code>&nbsp;: épaisseur d'un pli de peau au niveau du triceps,</li>
	<li><code>insulin</code>&nbsp;: insuline à 2 heures,</li>
	<li><code>mass</code>&nbsp;: IMC,</li>
	<li><code>pedigree</code>&nbsp;: pedigré diabétique,</li>
	<li><code>age</code>&nbsp;: âge.</li>
      </ul>

      <p>

	<b>À faire&nbsp;:</b> vous chargez ce jeu de données et vous commencez par explorer visuellement ses attributs comme on l'a fait avec les olives. (Visualiser la répartition des valeurs de chaque attribut séparément et visualiser ensuite les données en fonction de chaque paire d'attributs en colorant chaque point en fonction de sa classe.) Voyez-vous quelque chose&nbsp;? Arrivez-vous à trouver quel attribut pourrait être placé à la racine d'un arbre de décision&nbsp;?

	<br>
	<br>

	<b>À faire&nbsp;:</b> induire un arbre de décision comme on l'a fait lors du TP précédent. Mesurez son taux de succès sur le jeu de test et son taux de succès moyen et son écart-type dans une validation croisée à 10 plis.

      </p>

      <h2>Influence des paramètres de l'arbre induit</h2>

      <p>

	Lors de la création d'un arbre de décision, on dispose de paramètres optionnels qui peuvent être réglés. Ils peuvent avoir un impact important sur le taux d'erreur de l'arbre.

	<br>
	<br>

	En apprentissage supervisé, il faut toujours garder à l'esprit que le plus gros modèle n'est pas toujours le meilleur. Bien au contraire, très souvent, un modèle moins gros possède un taux d'erreur plus faible. C'est le cas avec les arbres de décision&nbsp;: ce n'est pas le plus grand arbre qui prédit le mieux.

	<br>
	<br>

	On va étudier trois paramètres&nbsp;:

      </p>

      <ul>
	<li>le nombre d'exemples minimum associés à une feuille,</li>
	<li>la mesure d'impureté,</li>
	<li>la profondeur de l'arbre.</li>
      </ul>

      <h3>Nombre d'exemples minimum associés à une feuille</h3>

      <p>

	Le paramètre <code>min_samples_leaf</code> de la méthode <code>tree.DecisionTreeClassifier()</code> indique le nombre minimum d'exemples qui sont associés à une feuille lors de l'induction de l'arbre. Par défaut, cette valeur est 1, ce qui est évidemment bien trop petit&nbsp;: avec un seul exemple d'entraînement par feuille, la feuille prédit la classe de cet exemple et cette feuille risque fort de provoquer du sur-apprentissage.

	<br>
	<br>

	<b>À faire&nbsp;:</b> en suivant la méthodologie vue lors du TP précédent, induire un arbre de décision pour ce jeu de données. (<i>I.e.</i>, vous découpez le jeu d'exemples en 80% d'exemples pour l'entraînement, les 20% restants pour le test puis vous induisez l'arbre.)
	<br>
	Ensuite, vous induisez 4 arbres pour lesquels vous spécifiez <code>min_samples_leaf</code> et donnez comme valeur 5, 10, 15, 20.
	<br>
	Vous mesurez l'erreur sur le jeu d'exemples de test de ces 5 arbres. Lequel donne la plus petite erreur&nbsp;?
	<br>
	Vous effectuez ensuite une validation croisée sur ces 5 arbres et mesurez le taux succès moyen et son écart-type pour chacun. Quel valeur du paramètre produit les arbres réalisant les meilleures prédictions&nbsp;?

      </p>

      <h3>Mesure d'impureté</h3>

      <p>

	Comme on l'a vu en cours, on peut mesurer l'impureté (comment les classes sont mélangées dans un jeu d'exemples) de différentes manières, en particulier l'impureté de Gini et l'entropie. Le paramètre <code>criterion</code> de la méthode <code>tree.DecisionTreeClassifier()</code> indique la mesure d'impureté à utiliser lors de l'induction. Par défaut, c'est l'impureté de Gini. Pour utiliser l'entropie, on indique <code>criterion="entropy"</code>.

	<br>
	<br>

	<b>À faire&nbsp;:</b> pour les 5 arbres construits précédemment, vous construisez 5 autres arbres en utilisant l'entropie. Vous mesurez les mêmes taux d'erreur et de succès et vous comparez. L'un des critères donne-t-il de meilleurs résultats&nbsp;? Quelle combinaison des deux paramètres que nous venons d'étudier donne les meilleurs résultats&nbsp;?

      </p>

      <h3>Profondeur de l'arbre</h3>

      <p>

	Le paramètre <code>depth</code> de la méthode <code>tree.DecisionTreeClassifier()</code> indique la profondeur maximale de l'arbre. Ce paramètre permet de limiter la taille de l'arbre.
	
	<br>
	<br>

	<b>À faire&nbsp;:</b> en utilisant les meilleurs paramètres trouvés ci-dessus, vous induisez des arbres dont la profondeur varie de 1 à 20. Vous mesurez leur taux d'erreur/taux de succès toujours de la même manière. Vous faites un graphique indiquez cette mesure en fonction de la profondeur. Qu'observez-vous&nbsp;?

	<br>
	<br>

	Ci-dessous, un graphique montrant le taux de succès en fonction de la profondeur de l'arbre induit&nbsp;:

      </p>

      <img src="cv_depth_1_19.png" width="300" alt="" >
      
      <p>

	Dans cette figure, outre le paramètre <code>depth</code> que l'on a fait varier, l'arbre est induit avec les paramètres <code>min_samples_leaf = 5, criterion = "entropy"</code>. Réalisez ce type de représentation graphique.
	
      </p>

<!--      <h3>Approche automatique</h3>

      <p>

	Nous décrivons maintenant une méthode permettant de déterminer de bons paramètres.

	
      </p>
-->  

      <h2>Attributs nominaux (ou catégoriques)</h2>

      <p>

	Les attributs nominaux sont faciles à traiter pour induire un arbre de décision mais malheureusement, <code>scikit_learn</code> ne sait pas le faire. Il faut utiliser des moyens détournés pour arriver à les prendre en compte, quoique de manière pas très satisfaisante. Comme c'est l'outil que l'on utilise, on va quand même voir comment faire avec cet outil. Mais je ne peux que vous encouragez à ne pas utiliser cette approche et à vous tourner vers un logiciel sérieux&nbsp;: R (ou encore <a href="">c4.5</a>). Malheureusement, nous n'avons pas le temps d'apprendre à utiliser R dans les quelques heures que dure ce module.

      </p>
      
      <h3>Principe de traitement des attributs nominaux</h3>
	
      <p>

	Nous allons illustrer le principe sur un jeu de données contenant des attributs nominaux et des attributs quantitatifs. Ce jeu de données est disponible à cette url <code>https://philippe-preux.github.io/ensg/miashs/datasets/enoughTip.csv</code>. Je suppose par la suite que vous avez chargé ce jeu de données dans un objet dénommé <code>tips</code>.

	<br>
	<br>

	Aux États-Unis (et dans d'autres pays), à moins d'être un goujat ou d'avoir été particulièrement mal traité par le serveur, on donne systématiquement un pourboire au restaurant et dans les bars. En effet, le service n'est pas inclus dans la note. En principe, ce pourboire s'élève à au moins 15% de la note.

	<br>

	Chaque ligne de ce jeu de données contient des informations concernant une tablée dans un restaurant&nbsp;:

      </p>

      <ul>
	<li><code>TOTBILL</code>&nbsp;: le montant de la note,</li>
	<li><code>TIP</code>&nbsp;: le montant du pourboire laissé par le client,</li>
	<li><code>SEX</code>&nbsp;: le genre du client ayant payé la note,</li>
	<li><code>SMOKER</code>&nbsp;: est-il fumeur ou pas&nbsp;?</li>
	<li><code>DAY</code>&nbsp;: le jour,</li>
	<li><code>TIME</code>&nbsp;: déjeuner ou dîner&nbsp;?</li>
	<li><code>SIZE</code>&nbsp;: taille de la tablée,</li>
	<li><code>enough</code>&nbsp;: est-ce que le pourboire est &ge; 15%&nbsp;?</li>
      </ul>

      <p>

	Les attributs <code>TOTBILL</code>, <code>TIP</code> et <code>SIZE</code> sont numériques. Les autres attributs sont nominaux. On veut prédire l'attribut <code>enough</code>.

	<br>

	Considérons l'attribut <code>DAY</code> qui vaut <code>sun</code>, <code>sat</code>, <code>fri</code>, ou <code>thurs</code>. Pour pouvoir construire un arbre de décision avec <code>scikit_learn</code>, nous devons le transformer en un attribut numérique. La méthode que l'on va utiliser doit fonctionner quel que soit le nombre de valeurs que peut prendre l'attribut (l'<em>arité</em> de l'attribut). Cet attribut prenant 4 valeurs différentes, il va être transformé en 4 attributs valant 0 ou 1&nbsp;: chacun de ces 4 attributs correspond donc à l'une des 4 valeurs possibles de l'attribut et 1 seul de ces 4 nouveaux attributs numériques vaudra 1.

	<br>

	Cela pourrait constituer un petit exercice de programmation, mais <code>pandas</code> dispose d'une fonction qui effectue cette transformation pour nous. Faites&nbsp;: <code>pd.get_dummies(tips.DAY).head()</code>. Cela affiche&nbsp;:
	<br>
	
	<pre>   fri   sat   sun   thurs 
0     0     0     1       0
1     0     0     1       0
2     0     0     1       0
3     0     0     1       0
4     0     0     1       0</pre>

	<br>

	alors que cet attribut vaut&nbsp;:

	<br>

	<pre>>>> tips.loc[:,"DAY"].head()
0    sun 
1    sun 
2    sun 
3    sun 
4    sun 
Name: DAY, dtype: object</pre>

	<br>

	On voit que la valeur d'origine de l'attribut est transformée en un <i>data frame</i> <code>pandas</code> composé de 4 colonnes, une colonne par valeur possible.

	<br>

	On peut regarder la fin du <i>data frame</i>&nbsp;

	<br>

	<pre>>>> tips.loc[:,"DAY"].tail()
239      sat 
240      sat 
241      sat 
242      sat 
243    thurs 
Name: DAY, dtype: object</pre>

	<br>

	qui se transforme en &nbsp;:

	<br>

	<pre>>>> pd.get_dummies(tips.DAY).tail()
     fri   sat   sun   thurs 
239     0     1     0       0
240     0     1     0       0
241     0     1     0       0
242     0     1     0       0
243     0     0     0       1</pre>

      <p>
	
	Maintenant que l'on sait transformer un attribut en un ensemble d'attributs numériques, il suffit d'ajouter ces 4 attributs au <i>data frame</i> et de retirer l'attribut nominal d'origine. Pour ajouter les colonnes, on utilise la méthode <code>join()</code> de <code>pandas</code>. Pour retirer une colonne, on utilise la méthode <code>drop ()</code> de <code>pandas</code>. Cela s'utilise de la manière suivante&nbsp;:

      </p>

      <pre>>>> tips = tips.join (pd.get_dummies(tips.DAY))
tips.drop (columns = ["DAY"], inplace=True)</pre>

      <p>

	Remarque&nbsp;: visiblement, il y a un bug dans pandas. Si on a préalablement indiqué que le type de <code>DAY</code> est catégorique (avec <code>tips ["DAY"] = tips ["DAY"]. astype ("category")</code>), le <code>join ()</code> plante, affiche une cinquantaine de lignes totalement incompréhensibles, ne me demandez pas pourquoi. Dans ce cas, il faut retirer le type catégorique de la colonne (<ode>tips ["DAY"] = tips ["DAY"]. astype ('O')</code>) avant de faire le <code>get_dummies()</code>.
	
	<br>
	<br>
	
	<b>À faire&nbsp;:</b> faites ce que je viens d'expliquer et traitez de la même manière les autres attributs nominaux (<code>SEX</code>, <code>SMOKER</code>, <code>TIME</code>).
	
	<br>
	
	Remarquez que vous pouvez retirer plusieurs colonnes en une seule instruction en indiquant leur nom dans le paramètre <code>columns</code> de la méthode <code>drop()</code>.
	
      </p>
      
      <h3>Induction d'un arbre de décision</h3>

      <p>

	Le <i>data frame</i> est maintenant utilisable par l'algorithme d'induction d'arbres de décision.

	<br>
	<br>

	<b>À faire&nbsp;:</b> en suivant la méthode vue précédemment, induire un arbre de décision. Essayez de l'améliorer en modifiant les paramètres de l'arbre.
	
      </p>
      
      <h2>Valeurs manquantes</h2>

      <p>


	À suivre.

	<!--Les valeurs manquantes sont omniprésentes dans les jeux de données réels. Pour ce TP, j'ai simplifié le jeu de données original (<code>https://philippe-preux.github.io/ensg/miashs/datasets/PimaIndiansDiabetes2.csv</code>) en retirant toutes les données ayant au moins un attribut dont la valeur est manquante.

	<br>
	<br>

	Face à un jeu d'exemples contenant des valeurs manquantes, l'approche la plus simple consiste à faire ce que l'on vient de faire&nbsp;: ne pas utiliser les exemples ayant une valeur manquante.

	<br>

	Les données manquantes étant omniprésentes, il est très tentant de vouloir leur affecter une valeur. Cependant, déterminer la, ou une, bonne valeur est un problème très difficile de manière générale.

	<br>

	Comme c'est un problème très courant, une méthode par défaut pour remplacer les valeurs manquantes par une valeur est généralement disponible. C'est le cas dans <code>scikit_learn</code> mais c'est il ne faut pas l'utiliser. Très souvent, cette méthode fait n'importe quoi en appliquant un traitement simple que rien ne justifie. C'est effectivement ce que fait la méthode par défaut de <code>scikit_learn</code>.

	<br>
	<br>

-->
      </p>

</div>

<!-- Default Statcounter code for on github
https://philippe-preux.github.io -->
<script>
  var sc_project=12923547; 
  var sc_invisible=1; 
  var sc_security="627600d4"; 
</script>
<script src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript>
  <div class="statcounter">
    <a title="Web Analytics" href="https://statcounter.com/" target="_blank">
      <img class="statcounter"
	   src="https://c.statcounter.com/12923547/0/627600d4/1/"
	   alt="Web Analytics"
	   referrerPolicy="no-referrer-when-downgrade"></a>
  </div>
</noscript>
  <!-- End of Statcounter Code -->
  
</body>
</html>
