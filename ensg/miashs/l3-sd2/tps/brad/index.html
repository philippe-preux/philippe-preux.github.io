<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Brad's sweet home</title>
  <link href="https://philippe-preux.github.io/css/ma.css" 
	rel="stylesheet" type="text/css" media="all" />
  <link rel="shortcut icon" type="image/x-icon" 
	href="https://philippe-preux.github.io/img/site.ico" />
</head>

<body>
<div class="tpR">

  <h1></h1>
  
  <p>

    Dans ce TP, on continue notre exploration de notions et techniques de base pour la science des données. On va notamment manipuler des fichiers de données beaucoup plus gros que précédemment et réaliser des tâches de régression.

    <br/>

    Tous les TPs précédents doivent impérativement avoir été faits.

    <br/>
    <br/>

    À l'issue de ce TP, vous m'envoyez par email un compte-rendu (format <kbd>odt</kbd>) indiquant la réponse aux questions qui sont posées. Vous m'envoyez également un fichier python réalisant toutes les manipulations de ce TP&nbsp;: je dois pouvoir exécuter ce fichier en tapant <kbd>python3 nom-de-votre-fichier.py</kbd> et reproduire vos résultats. Cette exécution ne doit pas provoquer d'erreur de python. Remarque&nbsp;: un <i>notebook</i> ne convient pas.
    
  </p>

  <h2>Introduction</h2>
    
  <p>

    Brad vit en altitude, dans les montagnes du Colorado (il y fait froid assez tôt dans l’automne et tardivement au printemps). Il a aménagé une station de collecte des températures. Ainsi, quatre thermomètres électroniques mesurent-ils la température dans son séjour, son bureau, son sous-sol et à l’extérieur de chez lui, toutes les 3 minutes. Ces thermomètres sont reliés à son ordinateur qui stocke chacune des mesures dans quatre fichiers, un fichier par thermomètre. On dispose de ces quatre fichiers qui contiennent plusieurs dizaines de milliers de mesures. Notre objectif est d’étudier les températures ainsi mesurées. On sait également que le thermostat de Brad est réglé à 21°C pendant la journée, à 16°C pendant la nuit.

    <br/>
    <br/>

    Ces 4 fichiers de données sont disponibles à ces 4 urls&nbsp;:

    <ul>
      <li><kbd>https://philippe-preux.github.io/ensg/miashs/datasets/brad-basement</kbd></li>
      <li><kbd>https://philippe-preux.github.io/ensg/miashs/datasets/brad-lab</kbd></li>
      <li><kbd>https://philippe-preux.github.io/ensg/miashs/datasets/brad-livingroom</kbd></li>
      <li><kbd>https://philippe-preux.github.io/ensg/miashs/datasets/brad-outside</kbd></li>
    </ul>

  <p>

    Ces 4 fichiers ont le même format. 
    Dans votre navigateur, regardez l'un d'eux.
    Vous constatez qu'il ne s'agit pas de fichiers <kbd>csv</kbd> et qu'ils n'ont pas d'en-tête avec le nom des attributs.

    <br/>

    Dans ces 4 fichiers, les colonnes sont séparées par un espace. Dans l'ordre, les colonnes correspondent aux informations suivantes&nbsp;:

  </p>

  <ul>
    <li>l'année</li>
    <li>le mois</li>
    <li>le quantième</li>
    <li>heure</li>
    <li>minute</li>
    <li>seconde</li>
    <li>température</li>
  </ul>

  <p>

    Les lignes de chacun de ces fichiers sont ordonnées chronologiquement.
    
    <br/>
    
    Pour lire ces fichiers, on utilisera la méthode <kbd>read_table ()</kbd>. Regardez la documentation pour utiliser les bons arguments.

  </p>  
  
  <h2>Construction d'un tableau de données</h2>

  <p>

    On doit donc rassembler le contenu de ces 4 fichiers dans un tableau de données. Cette fusion doit s'effectuer en fonction de l'instant de la mesure.
    
    <br/>

    On commence par lire chacun de ces fichiers en le stockant dans un tableau de données.
    
    <br/>

    Ensuite, on fusionne ces 4 tableaux de données pour n'en faire qu'un seul que nous dénommerons <kbd>brad</kbd>. Une fois cela, fait, on peut détruire les 4 tableaux de données (commande python <kbd>del</kbd>).

    <br/>
    <br/>

    <b>À faire&nbsp;:</b> comment construisez ce tableau de données <kbd>brad</kbd>&nbsp;?

    <br/>
    <br/>

    Remarque&nbsp;: bien entendu, lorsqu'on réalise une telle opération de fusion, on vérifie que tout se passe bien. Puisque nous allons ensuite travailler uniquement sur le tableau de données <kbd>brad</kbd>, si celui-ci, pour une raison ou une autre, n'est pas construit correctement, tout ce que nous ferons par la suite sera faux.
    <br/>
    Il faut donc impérativement passer quelques instants à s'assurer que <kbd>brad</kbd> a été correctement construit.
    <br/>
    Pour vous aider, je vous indique ci-dessous les début et fin de <kbd>brad</kbd> correctement chargé&nbsp;:

  </p>

<pre>
>>> brad.head()
     an  mois   j   h  mn  temp_b  temp_l  temp_lr  temp_o
0  2003     7  25  16   4    24.0     NaN     29.8    27.5
1  2003     7  25  16   7    24.0     NaN     29.8    27.3
2  2003     7  25  16  10    24.0     NaN     29.8    27.3
3  2003     7  25  16  13    24.1     NaN     29.8    27.4
4  2003     7  25  16  16    24.1     NaN     29.8    27.8
>>> brad.tail()
          an  mois   j   h  mn  temp_b  temp_l  temp_lr  temp_o
169831  2004     7  16  15  16    21.7    22.9     22.8    16.8
169832  2004     7  16  15  19    21.7    22.9     22.8    16.9
169833  2004     7  16  15  22    21.7    22.9     22.8    16.8
169834  2004     7  16  15  25    21.7    22.9     22.8    16.8
169835  2004     7  16  15  28    21.7    22.9     22.8    16.4
</pre>

  <p>

    Obtenez-vous le même résultat&nbsp;? Est-ce que votre tableau de données semble correct&nbsp;?
    
    <br/>
    <br/>
    
    J'ai nommé les colonnes correspondant aux différentes températures <kbd>temp_b</kbd> pour le sous-sol (<i>basement</i>), <kbd>temp_l</kbd> pour la laboratoire (<i>lab</i>),  <kbd>temp_lr</kbd> pour le salon (<i>living-room</i>) et <kbd>temp_o</kbd> pour l'extérieur (<i>outside</i>).

    <br/>

    Notez bien les <kbd>NaN</kbd>&nbsp;: vous devez les avoir aussi pour ces lignes-là.

    <br/>
    <br/>
    
    <b>Question&nbsp;:</b> qu'est ce que ces <kbd>NaN</kbd>&nbsp;? Que font-ils là&nbsp;? Quel est leur signification&nbsp;?
    
  </p>
  

  <h2>Exploration visuelle du jeu de données</h2>




  <h3>Dates</h3>

  <p>

  </p>
  
  <h2>Corrélation des températures&nbsp;?</h2>








<figure>
    <img src="./olives-italie.png" width="400pt"/>
    <figcaption><font size="-3">(Cette figure est issue du livre sur <a href="http://ggobi.org/book.html">ggobi</a>.)</font></figcaption>
  </figure>
  
  <p>

    Chaque olive étant par ailleurs caractérisée par sa teneur en certains acides, la question que nous étudions dans ce TP est&nbsp;: à partir de cette composition chimique, peut-on déterminer la provenance géographique de l'olive&nbsp;?

    <br/>

    Si on arrive à déterminer la provenance à partir de la composition chimique de l'olive, on peut garantir que la provenance indiquée est la bonne et pourquoi pas, détecter ainsi des tentatives de fraudes si ce n'est pas le cas.

    <br/>
    <br/>

    On va pratiquer en deux phases. Durant la première, on va explorer visuellement le jeu de données&nbsp;: la réponse à la question posée est-elle visible sur un ou des graphiques&nbsp;? Durant la seconde, on va utiliser un algorithme d'apprentissage automatique pour essayer de répondre à la question. Les deux approches ne sont pas exclusives, bien au contraire&nbsp;: la première guide le choix d'une méthode à appliquer lors de la seconde.
    
  </p>

  <h2>Premiers pas&nbsp;: approche graphique (exploration visuelle des données)</h2>

  <p>

    Face à un jeu de données, la première chose à faire et de l'explorer visuellement. Dans le cas où on souhaite prédire la valeur d'un attribut, on se pose la question&nbsp;: la réponse à la question qui est posée saute-t-elle aux yeux&nbsp;?

    <br/>

    Donc, on commence par faire des graphiques très simples pour voir s'il est possible de prédire la région de provenance de l'olive.

    On commence par la région car il y a 3 régions (attribut <kbd>region</kbd>) qui se découpent en 8 zones (attributs et <kbd>Area Name</kbd> et <kbd>area</kbd>). Il est donc probablement plus facile de déterminer la région que la zone.

    <br/>

    Cette exploration visuelle permet également d'orienter le choix d'un modèle pour réaliser la tâche de prédiction&nbsp;: si on voit des relations simples, on sait que des modèles simples pourront réaliser les prédictions voulues.
    
  </p>
  
  <h3>Visualisation univariée&nbsp;: répartition des valeurs de chaque attribut en fonction de sa classe</h3>
  
  <p>

    Par graphique très simple, on entend la visualisation de la répartition de la valeur d'un attribut (= univarié) en fonction de sa classe. Pour chaque acide, on réalise un graphique comme celui-ci pour l'attribut <kbd>palmitic</kbd>&nbsp;:

  </p>

  <p class="aligncenter">
    <img src="palmitic-par-classe.png" width="500pt" align="middle" />
  </p>

  <ul>
    <li>En ordonnées, c'est le numéro de la donnée (la ligne dans le jeu de données)&nbsp;;</li>
    <li>en abscisses, la valeur de l'attribut <kbd>palmitic</kbd>&nbsp;;</li>
    <li>la couleur indique la région&nbsp;:
      <ol>
	<li>sud de l'italie en bleu&nbsp;;</li>
	<li>Sardaigne en rose&nbsp;;</li>
	<li>nord de l'italie en jaune.</li>
      </ol></li>
  </ul>

  <p>

    D'un coup d'&oelig;il, on voit que cet attribut ne permet pas de distinguer les olives des 3 classes. Quand on considère une valeur de l'acide palmitique supérieure à 1400, on voit que l'on peut en déduire que l'olive provient de la zone 1&nbsp;: il n'y a que des points bleus pour ces abscisses&nbsp;: tout va bien. Par contre, si cette valeur est comprise entre 1000 et 1200, les 3 classes sont possibles&nbsp;: pour ces abscisses, on voit des points des 3 couleurs. Donc, si la teneur en acide palmitique est 1100, on ne peut pas déterminer la zone d'origine de l'olive.

    <br/>

    En conclusion, l'attribut <kbd>palmitic</kbd> ne permet pas de déterminer la région d'origine de l'olive.

    <br/>
    <br/>

    <b>À faire&nbsp;:</b> réalisez ce graphique pour chacun des 8 acides et concluez (vérifiez que vous obtenez bien le même graphique que moi pour l'acide palmitique). Y a-t-il un, ou des attributs, qui permet de déterminer la région d'origine&nbsp;? ou qui peut aider&nbsp;?

    <br/>

    Remarque&nbsp: pour réaliser ce graphique, j'ai ajouté une colonne <kbd>numero</kbd> au tableau de données <kbd>olives</kbd>. Cette colonne contient tout simplement le numéro de la donnée.

    <br/>
    <br/>

    <b>À faire&nbsp;:</b> sans dévoiler la solution, vous devez trouver un attribut qui sépare l'une des classes des deux autres. Pour celui-ci, vous obtenez un graphique qui ressemble à celui-ci&nbsp;:

  </p>

  <img src="allure-generale.png" width="500pt" />
  
  <p>

    Ce graphique montre que la classe 1 (points bleus) est facilement identifiée grace à cet attribut.

    <br/>
    
    Quand vous l'avez trouvé, vous pouvez vous concentrer sur les 2 classes qui sont encore mélangées (jaune et rouge) et recommencer le même raisonnement en vous occupant uniquement des données de ces deux classes. Vous devez trouver un attribut qui sépare bien les 2 classes restantes.

    <br/>

    Quels sont ces deux attributs et comment pouvez-vous déterminer la classe à partir de ces deux attributs&nbsp;?
    
  </p>

  <h3>Visualisation bivariée</h3>

  <p>

    «&nbsp;Bivariée&nbsp» signifie que l'on considère deux attributs.
    L'idée est ici la même que précédemment, mais au lieu de chercher une relation entre un attribut et la classe, on cherche une relation entre un couple d'attributs et la classe.

    <br/>

    Reprenons le schéma réalisé à la fin du TP précédent&nbsp;:
    
  </p>

  <img src="../graphiques/olives-palmitic-vs-oleic-against-region.png" width="500pt" />

  <p>

    On voit que ces deux attributs ne permettent pas de déterminer la classe de manière simple&nbsp;: les points des 3 couleurs sont mélangés.

    <br/>

    On peut quand même voir que pour une valeur de l'acide oléique inférieure à (environ) 7200, l'acide palmitique permet à peu près de bien prédire la classe 1 ou 3. Cela ne répond pas à notre question, mais c'est un élément d'information.

    <br/>
    <br/>

    Je pourrais vous demander de chercher s'il existe une paire d'attributs qui permettent de prédire la région d'origine des olives mais je sais que cette recherche sera vaine et qu'elle vous prendra du temps. Donc vous pouvez passer à la suite, ou quand même vérifier qu'il n'y a rien à voir de simple sur aucun de ces graphiques.
    
  </p>

  
  <h2>Approche automatique</h2>

  <p>

    Il arrive que l'approche visuelle ne permette pas de voir quelque chose (c'est rare). Quoiqu'il en soit, en complément de l'exploration visuelle, nous allons essayer de prédire la région d'origine de l'olive à l'aide de méthodes qui ont pour objectif d'apprendre un modèle réalisant ce type de prédiction.

    <br/>
    <br/>

    Face à un jeu de données de petite taille comme celui-ci (quelques centaines de lignes, une dizaine de colonnes, quelques classes), on commence par essayer une méthode qui généralement donne de très bons résultats, les arbres de décision. L'induction d'un arbre de décision est très souvent une méthode très efficace, très peu coûteuse en temps de calcul, qui donne de très bonnes performances pour la prédiction de la classe.

    <br/>
    <br/>

    Pour cela, on va utiliser la bibliotèque <kbd>scikit_learn</kbd>. Pour pouvoir créer des arbres de décision, on fera&nbsp;: <kbd>from sklearn import tree</kbd>.

    <br/>

    La documentation est <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree">là</a>.
    
  </p>

  
  <h3>Induction d'un arbre de décision</h3>

  <p>

    Pour induire un modèle, on fait comme suit&nbsp;: le jeu de données est découpé en deux parties, l'une utilisée pour induire le modèle, la seconde pour estimer la probabilité qu'il commette une erreur lors d'une prédiction.

    <br/>

    La première partie constitue les données d'entraînement, la seconde les données de test.

    <br/>

    Il est classique d'utiliser 80% des données disponibles comme données d'entraînement, les 20% restant constituant les données de test.

    <br/>

    La répartition entre les deux parties est faite aléatoirement. Il est important de vérifier que les données sont stratifiées, c'est-à-dire que la proportion des données de chaque classe est à peu près la même dans les deux parties.

    <br/>
    <br/>

    Pour découper le jeu de données en ces deux parties, on fait comme suit&nbsp;:

  </p>

  <ol>
    <li>on crée un vecteur de N nombres aléatoires uniformément répartis entre 0 et 1, où N est le nombre total de données. Pour cela, on utilise la fonction <kbd>random.rand (N)</kbd> du paquetage <kbd>numpy</kbd>. Appelons ce vecteur <kbd>v</kbd>.</li>
    <li>À partir de <kbd>v</kbd>, on construit un vecteur booléen qui contient 80% de valeurs <kbd>True</kbd>. Appelons ce vecteur <kbd>b</kbd>.</li>
    <li>On utilise <kbd>b</kbd> pour construire les deux jeux de données, l'un pour les données d'entraînement, l'autre pour les données de test. Appelons-les respectivement <kbd>olives_train</kbd> et <kbd>olives_test</kbd>.</li>
  </ol>
  
  <p>

    Nous pouvons maintenant induire l'arbre de décision.

    <br/>
    <br/>
    
    <b>À faire&nbsp;:</b>

    </p>

  <ol>
    <li>créer les deux jeux de données <kbd>olives_train</kbd> et <kbd>olives_test</kbd>.</li>
    <li>Vérifier que la propotion des données de chacun des 3 classes est à peu près la même dans les deux jeux de données.</li>
    <li>Induire un arbre de décision à partir de <kbd>olives_train</kbd>. Il y a beaucoup de paramètres qui peuvent être réglés mais nous nous en tiendrons à leur valeur par défaut dans un premier temps.</li>
  </ol>
  
  <h3>Diagnostic de l'arbre de décision</h3>

  <p>

    Avant même de regarder à quoi l'arbre ressemble, il est important de commencer par déterminer si cet arbre est capable de prédire la classe de manière précise. On va donc estimer la probabilité qu'il commette une erreur lorsqu'il prédit la classe d'une donnée. Pour cela, on&nbsp;:

  </p>

  <ul>
    <li>utilise les données de test que l'on a mises de côté dans <kbd>olives_test</kbd>,</li>
    <li>on utilise l'arbre pour prédire leur classe,</li>
    <li>on compare la classe prédite avec la classe de la donnée.</li>
    <li>On divise le nombre d'erreurs de prédiction par le nombre de données de test&nbsp;: cela nous fournit une estimation de la probabilité d'erreur.</li>
  </ul>
  
  <p>

    <b>À faire&nbsp;:</b> faites ce qui vient d'être expliqué. Quelle est la valeur de cette estimation&nbsp;?

    <br/>
    <br/>

    Il est intéressant de mesurer ce taux d'erreur pour chaque classe.

    <br/>

    <b>À faire&nbsp;:</b> mesurer le taux d'erreur pour chaque classe. Les 3 classes sont-elles toutes les 3 prédites correctement avec la même probabilité&nbsp;?
    
  </p>
  
  <h3>Interprétation d'un arbre de décision</h3>

  <p>

    On peut obtenir une visualisation de l'arbre de décision en faisant par exemple&nbsp;:
    
  </p>

<pre>import matplotlib as mpl
import matplotlib.pyplot as plt
fig, ax = plt.subplots ()
tree.plot_tree (arbre)
fig.show ()
</pre>

  <p>
    
    qui ouvre une fenêtre avec le graphique suivant&nbsp;:

  </p>
  
  <img src="arbre-region.png" width="500pt" />

  <p>
    
    <b>À faire&nbsp;:</b> réalisez ce graphique et le comprendre. En particulier, comprendre ce qui est affiché dans chaque n&oelig;ud.

    <br/>
    <br/>

    Les tests réalisés à chaque n&oelig;ud sont difficile à comprendre. Pour afficher le nom des attributs, on ajoutera <kbd>feature_names = list (olives_test)</kbd> dans l'appel de la méthode <kbd>plot_tree()</kbd>. Et on obtient&nbsp;:
    
  </p>

  <img src="arbre-region-avec-le-nom-des-attributs.png" width="500pt" />

  <p>

    En consultant <a hef="https://scikit-learn.org/stable/modules/tree.html#tree">la documentation</a>, on peut avoir une représentation plus jolie et informative avec la classe prédite qui est indiquée dans chaque feuille, comme celle-ci&nbsp;:

  </p>
  
  <img src="arbre-region-plus-joli.png" width="500pt" />

  <p>

    <b>Faites-le.</b>

    <br/>
    <br/>

    Un arbre de décision peut facilement être transformé en un ensemble de règles de décision. Ici l'arbre est très petit, c'est facile.

    <br/>

    <b>Faites-le&nbsp;: quelles sont ces règles&nbsp;?</b>
    
  </p>

  
  <h3>Test de l'arbre de décision</h3>

  <p>

    Nous avons construit un arbre de décision qui donne de très bons résultats. Est-ce juste de la chance ou est-ce que décidément, cette tâche se résout facilement à l'aide d'un arbre de décision&nbsp;?

    <br/>
    <br/>

    Pour apporter des éléments de réponse à cette question, on refait plusieurs fois la construction de l'arbre de décision en découpant le jeu de données aléatoirement à chaque fois. Par exemple, on peut refaire toute cette procédure 30 fois (ou 100, ...). Pour chaque arbre induit, on estime sa probabilité d'erreur de prédiction que l'on stocke. Une fois les 30 (ou 100, ...) constructions réalisées, on vérifie que la probabilité d'erreur varie, peu, un peu, beaucoup, ... Si elle varie peu, c'est très bon signe&nbsp;: tous les arbres induits ont à peu près la même précision, qui est très bonne pour la prédiction de la région d'origine de l'olive.

    <br/>
    <br/>

    <b>À faire&nbsp;:</b> effectuer ce qui vient d'être expliqué. Que pensez-vous du résultat&nbsp;?

  </p>

  <h3>Reproductibilité</h3>
  
  <p>

    Pour construire les jeux de données d'entraînement et de test, nous avons utilisé des nombres générés pseudo-aléatoirement. Si vous effectuez ce qui a été expliqué plus haut pour l'induction d'un arbre deux fois de suite, vous obtiendrez des résultats différents (dans le cas présent, la différence est petite). Il est important de pouvoir reproduire les résultats que vous avez obtenu. Pour cela, il faut que les nombres pseudo-aléatoires qui sont générés soient les mêmes d'une exécution à la suivante. Pour obtenir ce résultat, il faut initialiser la <i>graine</i> du générateur de nombres pseudo-aléatoires.
    <!--
	Ces nombres étant générés dans le paquetage <kbd>numpy</kbd>, il faut initialiser cette graine dès que ce paquetage a été chargé. Pour cela, on exécute l'instruction <kbd>np.random.seed (le-nombre-que-vous-voulez)</kbd> où vous remplacez <kbd>le-nombre-que-vous-voulez</kbd> par le nombre que vous voulez, éventuellement avec beaucoup de chiffres. -->
    On fait ainsi&nbsp;:

  </p>
  
<pre>
graine = int ("ScienceDesDonnees", base=36)%2**31
rs = np.random.RandomState (graine)
</pre>

  <p>
    
    <kbd>graine</kbd> est un entier. La première ligne transforme une chaîne de caractères quelconque en un entier. Ensuite, on initialise le générateur de nombres pseudo-aléatoires.

    <br/>
    
    Puis, lors de l'induction de l'arbre de décision, on passe celui-ci en paramètre&nbsp;:

  </p>
  
<pre>
DecisionTreeClassifier (random_state = rs)
</pre>

  <p>
    
    <br/>
    <br/>

    <b>À faire&nbsp;:</b> effectuer l'initialisation de cette graine et refaites toute la procédure d'induction d'arbre. Estimer sa probabiité d'erreur. Si vous effectuez cela plusieurs fois, vous devez obtenir exactement le même résultat à chaque fois.
    
  </p>

  <h2>Pour finir...</h2>

  <p>

    Refaites le même travail pour prédire l'attribut <kbd>area</kbd>.
    
  </p>
  
</div>

<!-- Default Statcounter code for on github
https://philippe-preux.github.io -->
<script type="text/javascript">
var sc_project=12923547; 
var sc_invisible=1; 
var sc_security="627600d4"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12923547/0/627600d4/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
  <!-- End of Statcounter Code -->
  
</body>
</html>
