<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Classification non supervisée&nbsp;: partitionnement d'un jeu de données</title>
    <link href="https://philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all">
    <!--link href="file:///home/ppreux/philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all"-->
    <link rel="shortcut icon" type="image/x-icon" 
	  href="https://philippe-preux.github.io/img/site.ico">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
      .aligncenter {
	  text-align: center;
      }
      span.petit {
	  font-size: 8px;
      }
    </style>
  </head>
  
  <body>
    <div class="tpR">

      <h1>Classification non supervisée&nbsp;: partitionnement d'un jeu de données</h1>

      <p>

	Dans ce TP, nous abordons la classification non supervisée, en particulier les méthodes de partitionnement, ou segmentation, de données, <i>clustering</i> en anglais.

	On pourra consulter mes <a href="https://philippe-preux.github.io/Documents/notes-de-cours-de-fouille-de-donnees.pdf">notes de cours de fouille de données</a> pour une présentation de la classification non supervisée (chapitre 10).

	<br>
	<br>

	À l'issue de ce TP, vous m'envoyez par email un compte-rendu (format <kbd>odt</kbd> ou <kbd>pdf</kbd>) indiquant la réponse aux questions qui sont posées. Vous m'envoyez également un fichier python réalisant toutes les manipulations de ce TP&nbsp;: je dois pouvoir exécuter ce fichier en tapant <kbd>python3 nom-de-votre-fichier.py</kbd> et reproduire vos résultats. Cette exécution ne doit pas provoquer d'erreur de python. Remarque&nbsp;: un <i>notebook</i> ne convient pas.

      </p>

      <h2>Introduction</h2>

      <p>

	Nous allons commencer par la méthode probablement la plus connue, les k-moyennes (<i>k-means</i> en anglais) qui a été décrite en cours. Au besoin, se référer à mon polycopié concernant cette méthode.

	<br>

	Par rapport à la classification supervisée, la classification non supervisée a ceci de particulier que l'on ne connait pas la valeur à prédire. Aussi, juger de la qualité d'un partitionnement est-il quelque chose qui est difficile à juger.

	<br>

	Là encore, à chaque fois que cela est possible, une exploration visuelle des données est essentielle que ce soit avant d'appliquer un algorithme de partitionnement de données pour essayer de voir ce qu'il semble raisonnable que l'algorithme produise et ensuite, pour juger le résultat produit par l'algorithme. Comme tous les algorithmes, ceux de partionnement font toujours quelque chose, il calcule toujours un résultat. Ils sont incapables de juger si ce qu'ils ont fait est pertinent&nbsp;: seul l'humain peut le déterminer en anticipant sur le résultat que devrait produire l'algorithme et en jugeant le résultat produit par l'algorithme.
    
      </p>

      <h2>K-moyennes</h2>

      <h3>Description de la méthode <code>KMeans ()</code> de scikit_learn</h3>

      <p>

	On utilise la méthode <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans">KMeans ()</a> de scikit_learn. Sous sa forme la plus simple, on l'utilise comme suit. On commence par créer un objet <code>Kmeans</code>&nbsp;:

	<br>

	<code>partitionneur = sklearn.cluster.KMeans (nombre_de_parties, random_state)</code>

	<br>

	que l'on peut ensuite appliquer à un jeu de données contenu dans une matrice <code>X</code>&nbsp;:

	<br>

	<code>partition = partitionneur. fit (X)</code>

	<br>

	L'objet <code>partition</code> contient différentes informations&nbsp;:
	
      </p>

      <ul>
	<li><code>partition. clusters_centers_</code> contient les coordonnées des centroïdes,</li>
	<li><code>partition. labels_</code> contient le numéro de partie de chaque donnée,</li>
	<li><code>partition. inertia_</code> contient l'inertie intraclasse de la partition.</li>
      </ul>

      <p>

	Les deux paramètres de <code>KMeans ()</code> indiqués plus haut sont&nbsp;:

      </p>

      <ul>
	<li><code>nombre_de_parties</code> qui spcifie le nombre de parties qui doivent être constituées (donc le nombre de centroïdes),</li>
	<li><code>random_state</code> que l'on a rencontré au semestre précédent.</li>
      </ul>

      <h3>Mise en application</h3>

      <p>

	On va mettre en application la méthode <code>KMeans ()</code> sur ce <a href="https://philippe-preux.github.io/ensg/miashs/fouilleDeDonneesII/tp/k-moyennes/jeu1.txt"> jeu de données</a>.

	<br>

	Pour cela&nbsp;:
	
      </p>

      <ol>
	<li>lire le jeu de données dans un tableau de données.</li>
	<li>Visualiser ce jeu de données&nbsp;: que voyez-vous&nbsp;? que va faire faire l'algorithme des k-moyennes&nbsp;?</li>
	<li>Partionner le jeu de données avec la méthode <code>KMeans ()</code></li>
	<li>Visualisez le résultat en utilisant une couleur différente pour chacune des partie. Le résultat est-il conforme à vos attentes&bsp;?</li>
      </ol>

      <h3>Allons plus loin&nbsp;: déterminer le nombre de parties</h3>

      <p>

	L'une des difficultés rencontrées en partitionnement de données concerne la détermination du nombre de parties. Sur l'exemple que nous venons de traiter, ce nombre est évident, il saute aux yeux. Sur des données réelles, c'est rarement le cas. On va utiliser ce jeu de données très simple pour voir comment déterminer ce nombre de parties vraisemblablement le meilleur. On va voir deux méthodes, l'une basée sur l'inertie, l'autre sur le score de silhouette.

	<br>

	Dans les deux cas, l'idée est simple&nbsp;: on calcule des partitions avec des nombres de parties variant par exemple de 2 à 10 et on utilise un score pour déterminer le «&nbsp;bon&nbsp;» nombre de parties.

	<br>
	<br>
	
	<b>Déterminer le nombre de groupes avec l'inertie</b>

	<br>

	Effectuer des partitionnements pour un nombre de parties variant de 2 à 10. Pour chaque partitionnement, stocker son inertie dans une liste. Ensuite, visualiser l'inertie en fonction du nombre de groupes et déterminer le coude.

	<br>

	Que trouvez-vous&nbsp;?
	
	<br>
	<br>
	
	<b>Déterminer le nombre de groupes par le score de silhouette</b>

	<br>

	Le principe est le même mais avant cela, je dois expliquer comment on calcule le coefficient de silhouette.

	<br>

	On utilise la méthode <code>sklearn.metrics.silhouette_score (X, cluster_labels)</code> où <code>X</code> est le jeu de données à partionner et <code>cluster_labels</code> est le numéro de partie assigné à chaque donnée.

	<br>
	
	Effectuer des partitionnements pour un nombre de parties variant de 2 à 10. Pour chaque partitionnement, calculer son coefficient de silhouette et stocker le liste. Ensuite, déterminer le nombre de parties qui maximise ce score. Il est intéressant également de visualiser ce coefficient en fonction du nombre de parties.
	<br>

	Que trouvez-vous&nbsp;? La même chose qu'avec l'inertie&nbsp;?

      </p>

      <h3>Allons encore plus loin&nbsp;: initialisation des centroïdes</h3>
      
      <p>

	Dans la méthode des k-moyennes, l'initialisation des centroïdes détermine l'issue de la partition puisque l'algorithme est déterministe. Aussi cette initialisation est-elle très importante&nbsp;: une mauvaise initialisation peut entraîner de mauvais résultats.

	<br>

	Tel qu'utilisé jusqu'ici, la méthode <code>KMeans ()</code> initialise automatiquement les centroïdes en utilisant un algorithme qui généralement donne de bons résultats. Néanmoins, il peut arriver que cet algorithme initialise mal les centroïdes. Aussi, il est toujours prudent de comparer les résultats obtenus avec cette initialisation et d'autres, par exemple une initialisation au hasard. Pour cela, il faut ajouter le paramètre <code>init = "random"</code> lors de l'appel de <code>KMeans ()</code>.

	<br>

	Tester cette initialisation aléatoire&nbsp;: effectuer par exemple 10 exécutions de <code>KMeans ()</code> avec une initialisation aléatoire. On mesure la qualité du partitionnement à l'aide de l'inertie et du coefficient de silhouette. Trouvez-vous de meilleurs partionnements&nbsp;?

      </p>

      <h3>Activités en autonomie</h3>

      <p>

	Appliquer tout ce qui vient d'être expliqué aux jeux de données suivants~:

      </p>

      <ul>
	<li><a href="./jeu1a.txt">ce fichier</a></li>
	<li>les iris qui sont disponibles dans scikit_learn en faisant <code>sklearn.datasets.load_iris ().data</code>.</li>
	<li><a href="https://philippe-preux.github.io/ensg/miashs/fouilleDeDonneesII/tp/k-moyennes/jeu4.txt">ce fichier</a></li>
	<li><a href="https://philippe-preux.github.io/ensg/miashs/fouilleDeDonneesII/tp/k-moyennes/jeu5.txt">ce fichier</a></li>
	<li><a href="https://philippe-preux.github.io/ensg/miashs/fouilleDeDonneesII/tp/k-moyennes/jeu11.txt">ce fichier</a></li>
      </ul>

      <p>

	Dans chaque cas, il faut essayer de déterminer le nombre de groupes. Comme d'habitude et rappelé en début de TP, il faut visualiser les données avant d'essayer de les partitionner afin d'essayer de voir ce que l'on aimerait obtenir et ce que l'algorithme des k-moyennes devrait calculer, et ensuite, visualiser le résultat et constater l'accord ou le désaccord entre ce que l'on attendait et ce que l'on a obtenu. En cas de désaccord, comprendre son origine..

      </p>

    </div>

<!-- Default Statcounter code for on github
https://philippe-preux.github.io -->
<script>
  var sc_project=12923547; 
  var sc_invisible=1; 
  var sc_security="627600d4"; 
</script>
<script src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript>
  <div class="statcounter">
    <a title="Web Analytics" href="https://statcounter.com/" target="_blank">
      <img class="statcounter"
	   src="https://c.statcounter.com/12923547/0/627600d4/1/"
	   alt="Web Analytics"
	   referrerPolicy="no-referrer-when-downgrade"></a>
  </div>
</noscript>
  <!-- End of Statcounter Code -->
  
</body>
</html>
