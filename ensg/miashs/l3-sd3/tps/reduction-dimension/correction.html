<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr" lang="fr">
  
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Réduction de dimension&nbsp;: éléments de correction</title>
    <link href="https://philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all">
    <link href="file:///home/ppreux/philippe-preux.github.io/css/ma.css" 
	  rel="stylesheet" type="text/css" media="all">
    <link rel="shortcut icon" type="image/x-icon" 
	  href="https://philippe-preux.github.io/img/site.ico">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
      .aligncenter {
	  text-align: center;
      }
      span.petit {
	  font-size: 8px;
      }
    </style>
  </head>
  
  <body>
    <div class="tpR">

      <h1>Réduction de dimension&nbsp;: éléments de correction</h1>

      <p>

	Dans ce TP, nous abordons la réduction de dimension d'un jeu de données, en particulier l'analyse en composantes principales, méthode très connue, très utile et très utilisée.

	On pourra consulter mes <a href="https://philippe-preux.github.io/Documents/notes-de-cours-de-fouille-de-donnees.pdf">notes de cours de fouille de données</a> pour une présentation de la réduction de dimension (chapitre 11).

	<br>
	<br>

	À l'issue de ce TP, vous m'envoyez par email un compte-rendu (format <kbd>pdf</kbd>) indiquant la réponse aux questions qui sont posées. Vous m'envoyez également un fichier python réalisant toutes les manipulations de ce TP&nbsp;: je dois pouvoir exécuter ce fichier en tapant <kbd>python3 nom-de-votre-fichier.py</kbd> et reproduire vos résultats. Cette exécution ne doit pas provoquer d'erreur de python. Remarque&nbsp;: un <i>notebook</i> ne convient pas.

      </p>

      <div class="correction">
	J'indique quelques éléments de correction mais tout a été vu en cours, décrit dans on poly et explique dans le sujet du TP. Donc, voir ses notes, le poly et le sujet.
      </div>
      
      <h2>Introduction</h2>

      <p>

	La réduction de dimension a pour objectif de diminuer le nombre d'attributs d'un jeu de données, en se concentrant sur des attributs réellement pertinents. D'un point de vue géométrique, son objectif est de déterminer le sous-espace (la variété) dans lequel les données vivent.

	<br>
	<br>

	Là encore, à chaque fois que cela est possible, une exploration visuelle des données est essentielle pour anticiper et comprendre.
    
      </p>

      <h2>Analyse en composantes principales</h2>

      <h3>Description de l'objet <code>PCA</code> de scikit_learn</h3>

      <p>

	On utilise la méthode <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA">PCA ()</a> de scikit_learn. Sous sa forme la plus simple, on l'utilise comme suit. On commence par créer un objet <code>PCA</code>&nbsp;:

	<br>

	<code>acp = sklearn.decomposition.PCA ()</code>

	<br>

	que l'on applique ensuite sur un jeu de données centrées réduites contenu dans une matrice <code>X</code>&nbsp;:

	<br>

	<code>acp.fit (X)</code>

	<br>

	Remarque&nbsp;: on peut utiliser un objet <code>scaler()</code> mais cette méthode est buggée&nbsp;: le calcul de l'écart-type est faux car la moyenne est estimée et non pas connue, donc le dénominateur doit être N-1 et non N, où N est le nombre de données. Si N est grand cela ne fait pas de grande différence&nbsp;; si N est petit, il vaut mieux faire le centrage et la réduction «&nbsp;à la main&nbsp;». Pour obtenir la valeur correcte de la variance, il faut ajouter l'option <code>ddof = 1</code> à l'appel de la méthode <code>numpy. var ()</code>.

	<br>

	L'objet <code>acp</code> contient différentes informations&nbsp;:

      </p>

      <ul>
	<li><code>acp. explained_variance_</code> contient les valeurs propres dans l'ordre décroissant. Ce sont donc les variances selon les différents axes principaux.</li>
	<li><code>acp. components_</code>&nbsp;: chaque ligne contient un vecteur propre, donc une direction principale. Le vecteur en i<sup>è</sup> ligne correspond à la i<sup>è</sup> valeur propre.</li>
	<li><code>acp. explained_variance_ratio_</code> contient la proportion de variance expliquée de chacun des axes principaux.</li>
      </ul>

      
      <h3>Mise en application</h3>

      <p>

	On va mettre en application l'analyse en composante principale sur un petit jeu de données disponible <a href="https://philippe-preux.github.io/ensg/miashs/datasets/eleves.txt">là</a>. Il contient les caractéristiques de 10 élèves&nbsp;: leur taille, leur poids, leur âge et leur moyenne.

	<br>

	<b>À faire&nbsp;:</b>
	
      </p>
      
      <ol>
	<li>lire le jeu de données dans un tableau de données.</li>
	<li>centrer et réduire les attributs.</li>
	<li>Visualiser ce jeu de données&nbsp;: que voyez-vous&nbsp;?

	  <div class="correction">
	    On fait les graphiques habituels et on ne voit pas grand chose.
	  </div>
	  
	</li>
	<li>En réaliser l'ACP.

	  <div class="correction">
	    Faire ce qui a été expliqué ci-dessus.
	  </div>

	</li>
      </ol>

      <p>

	Pour l'instant, on a fait des calculs qui n'ont pas beaucoup d'intérêt en tant que tel.	
	Nous abordons maintenant la partie vraiment importante&nbsp;: l'interprétation de ces calculs savants.

	<br>

	Commençons par observer et visualiser la proportion de variance expliquée par les composantes principales successives. Faites un graphique comme celui-ci&nbsp;:

	<br>

	<img src="eleves.Scree-plot.png" width="400pt" alt="Scree-plot élèves" >
	
	<br>

      </p>

      <div class="correction">
	Ce graphique est obtenu avec <code>acp.explained_variance_</code>. Aucune difficulté.
      </div>

      <p>
	
	Qu'en déduisez-vous&nbsp;?

      </p>

      <div class="correction">
	On voit que les deux premiers facteurs contiennent presque toute l'information.
      </div>

      <p>
	
	Une autre manière de représenter ces mêmes données consiste à visualiser le cumul de proportion de variance expliquée, comme ci-dessous&nbsp;:

	<br>

	<img src="eleves.fraction-de-variance-cumulée.png" width="400pt" alt="Cumul des proportions de variance expliquée." />

      </p>

      <div class="correction">
	Ce graphique est obtenu avec <code>acp.explained_variance_ratio_</code>. Aucune difficulté.
      </div>

      <p>
	
	On voit bien que le plan principal contient 80% de l'information, donc la projection dans ce plan est informative. Parfois, le plan principal comporte peu d'information (10, 20%). On en verra un exemple dans le travail en autonomie.
	
	<br>

	On peut ensuite visualiser les données dans les plans principaux. Les coordonnées des données dans l'espace factoriel sont obtenues par <code>acp. transform (X)</code>.

	<br>

	<b>À faire&nbsp;:</b> représenter les données dans le plan principal et dans le plan défini par les axes principaux 1 et 3.

      </p>

      <div class="correction">
	Comme dit ci-dessus, les coordonnées des points sur les axes principaux 1, 2 et 3 sont disponibles dans les colonnes 0, 1 et 2 de <code>acp. transform (X)</code>. Donc, il suffit de faire des graphiques avec les colonnes 0 et 1 d'une part, les colonnes 0 et 2 d'autre part pour obtenir les représentations demandées.
      </div>

      <p>
	
	<br>

	J'obtiens cela&nbsp;:
	
	<br>

	<img src="eleves.plan.1x2.png" width="400pt" alt="eleves dans le plan principal 1x2" />
	<img src="eleves.plan.1x3.png" width="400pt" alt="eleves dans le plan principal 1x3" />

	<br>

	Pensez-vous que le second graphique (plan principal 1x3) soit pertinent&nbsp;?

      </p>

      <div class="correction">
	Comme vu ci-dessus, l'axe 3 contient peu d'information. Donc, ce graphique des points dans le plan principal 1x3 n'est pas très informatif.
      </div>

      <p>

	Comme on l'a vu en cours, le fait de réduire la dimension déforme le nuage de points. Il faut donc calculer cette déformation pour chaque donnée et écarter ou du moins identifier les données dont la projection dans un plan principal n'est pas fidèle à sa position relative dans l'espace des données. Pour cela, on mesure le cosinus au carré de l'angle entre la demi-droite passant par l'origine et cette donnée d'une part et le plan principal que l'on considère d'autre part. Si ce cosinus au carré est inférieur à 0,3, la déformation est importante (angle > 57°).

	<br>

	<b>À faire&nbsp;:</b> sur le graphique précédent, identifier les points dont la projection est déformée et les affichez avec une couleur particulière.

      </p>

      <div class="correction">
	Il suffit de calculer la formule vue en cours et d'indiquer sur le graphique les points dont le cosinus est inférieur à 0,3 avec une couleur.
      </div>

      <p>

	J'obtiens cela&nbsp;:
	
	<br>

	<img src="eleves.plan.1x2.anomalies.png" width="400pt" alt="eleves dans le plan principal 1x2" />
	<img src="eleves.plan.1x3.anomalies.png" width="400pt" alt="eleves dans le plan principal 1x3" />

	<br>
	<br>

	Il faut déterminer le nombre de dimensions dans l'espace factoriel qui sont pertinentes. Pour cela, on utilise la proportion de variance expliquée par chacun des facteurs, autrement dit, les valeurs propres de la décomposition spectrale. Le creux du coude indique ce nombre.

	<br>

	<b>À faire&nbsp;:</b> faire un graphique indiquant la proportion de variance expliquée. Déterminer la dimension de l'espace factoriel.

      </p>

      <div class="correction">
	Le graphique a été fait plus haut. Le coude est clairement observé pour 2.
      </div>

      <p>

	Les axes principaux correspondent à des combinaisons linéaires des attributs originaux. La corrélation entre ces axes et les attributs originaux indique l'information que contient chaque axe principal par rapport aux attributs initiaux. On peut calculer, afficher et analyser ces nombres. On peut aussi réaliser le cercle de corrélation. Le faire.

	<br>
	
	J'obtiens cela&nbsp;:
	
	<br>

	<img src="eleves.cercle.corrélation.png" width="400pt" alt="cercle de corrélation" >
	
      </p>
      </p>

      <div class="correction">
	Encore une fois, c'est l'application directe du cours. On calcule les coordonnées des attributs initiaux du jeu de données avec les formules qui ont été vues.
	<br>
	Pour tracer un cercle de rayon 1, on peut calculer les coordonnées de des points de ce cercle tous les degrés (cosinus et sinus des angles variant de 0 à 2&pi;) et afficher ces 360 points.
	<br>
	Petit truc&nbsp;: pour que le cercle ressemble à un cercle et non pas à un ovale, il faut spécifier <code>ax. set_aspect (1)</code> qui fait en sorte que la longueur correspondant à une unité soit la même horizontalement et verticalement.
	<br>
	Sur ce cercle, on voit une forte corrélation positive entre le premier axe factoriel et la moyenne de l'élève (0,83) et une forte corrélation négative avec son poids (-0,79). Le premier axe est également assez fortement corrélé avec l'âge (-0,69) et la taille de l'élève (-0,78), lesquels sont assez corrélés avec le second axe. Avec des coefficients de corrélation aussi élevés entre les 4 attributs décrivant les élèves et le premier axe factoriel, la projection des points dans le plan principal est une représentation assez fidèle de la réparition des points dans l'espace initial à 4 dimensions.
	<br>
	Si on identifie par leur numéro les élèves dans leur projection dans le plan principal comme ci-dessous&nbsp;:
	<br>
	<img src="eleves.identifiés.plan.1x2.anomalies.png" width="400pt" alt="" />
	<br>
	(c'est le même graphique que plus haut, mais ici les élèves sont repérés par leur numéro), on peut combiner cette projection avec le cercle de corrélation pour effectuer les observations suivantes&nbsp;:
	<ul>
	  <li>les élèves 1, 2 et 3 ont une bonne moyenne (axe 1 fortement corrélé avec la mopyenne) mais sont plus plutôt plus petit, moins lourd et moins âgés que les autres (car cet axe est corrélé négativement avec ces 3 attributs).</li>
	  <li>Inversement, les élèves 4, 5, 6, 7 et 10 ont plutôt une moyenne plus faible mais sont plus âgés, plus lourds et plus grands.</li>
	  <li>Par sa position au centre du graphique, coordonnée positive sur l'axe 1 et coordonnée légérement négative sur l'axe 2, l'élève 8 a une note légérement supérieure à la moyenne des élvèes (coordonnée sur l'axe 1 positive), il est plus âgé que la moyenne, plus grand et plus lourd. Comme on l'a vu plus haut, sa position dans la projection sur le plan principal n'est pas fidèle à sa position vis-à-vis des autres élèves dans l'espace à 4 dimension.</li>
	  <li>L'élève 9 a une position très excentrée. Il a une note très supérieure à la moyenne (major de promo), il est l'un des plus âgés, tout en étant petit par rapport à la moyenne. Quoiqu'en position excentré, sa position dans le plan principal reflète fidélement sa position vis-à-vis des autres élèves dans l'espace initial à 4 dimensions.</li>
	  <li>Ces deux derniers exemples montrent que la position dans le graphique ne donne pas d'information sur la fidélité de la projection&nbsp;: l'élève excentré (9) est bien atypique par rapport aux autres, alors qu'un élève en plein centre de la projection (8) est lui mal représenté dans le plan principal.
	</ul>
      </div>

      <p>

      <h3>Activités en autonomie</h3>

      <p>

	Appliquer ce qui vient d'être expliqué aux jeux de données suivants&nbsp;:

      </p>

      <ul>
	<li>Les iris qui sont disponibles dans scikit_learn en faisant <code>sklearn.datasets.load_iris ().data</code>. Faites-en une ACP. Quand vous visualisez les iris, il est intéressant d'utiliser une couleur différente pour chacune des classes.

	  <div class="correction">
	    Fraction de variance cumulée&nbsp;:
	    <br>
	    <img src="iris.fraction-de-variance-cumulée.png" width="400pt" alt="ACP des iris" />
	    <br>
	    Il est clair que deux composantes fournissent une représentation très fidèle des iris.
	    <br/>
	    La projection des iris dans le plan principal (la couleur indique la classe) est donc très représentative.
	    <br>
	    <img src="ACP.plan-principal.iris.png" width="400pt" alt="ACP des iris" />
	    <br>
	    En calculant la déformation (cosinus), on voit qu'une seule donnée est projetée avec une déformation importante.
	  </div>
	  
	</li>
	<!--li><a href="https://philippe-preux.github.io/ensg/miashs/l3-sd2/tp/cc2/sleep.csv">Ce fichier</a> (que l'on a déjà rencontré). Retirez les données ayant des NAs avant d'en faire une ACP.</li-->
	<li>Réalisant une projection de données dans un plan, l'ACP permet de visualiser dans le plan des données décrites par de nombreux attributs. C'est ce que nous faisons pour ce jeu de données et le suivant.

	  <br>

	  <a href="https://philippe-preux.github.io/ensg/miashs/datasets/eurodist.txt">Ce fichier</a> contient une matrice qui indique la distance routière entre chaque couple parmi 21 villes européennes. À partir de ces distances, on aimerait obtenir une visualisation en 2 dimensions de la position des villes les unes par rapport aux autres. Projeter ce jeu de données dans le plan principal&nbsp;: chaque donnée correspondant à une ville, afficher le nom de la ville à sa position dans le plan principal. Vous devez obtenir un graphique comme celui-ci&nbsp;:
	  <br>

	  <img src="exemple-de-ce-qui-est-attendu.png" width="400pt" alt="exemple de graphique attendu" />
	  
	  <br>

	  Attention, ce graphique n'est absolument pas celui que vous devez obtenir. Je l'indique juste pour vous montrer le type de graphique attendu&nbsp;: la position des villes dans le plan.
	  
	  <br>
	  
	  Que constatez-vous&nbsp;? (Bien sûr, on aimerait que la position des villes corresponde à peu près à leur position sur une carte géographique.) Comment pouvez-vous déterminer si cette représentation en 2D est fidèle au jeu de données&nbsp;?

	  <div class="correction">
	    On obtient cette figure&nbsp;:
	    <br>
	    <img src="acp.villes.png" width="400pt" alt="" />
	    <br>
	    Le résultat est cohérent par certains côtés, incohérent par d'autres. Le bas de la figure est plutôt correct mais trouver Cherbourg à côté de Paris et Genève ne l'est pas. De même pour Milan entre Calais et Bruxelles, ou Vienne entre Hambourg et Copenhagen. En rouge est indiquée la seule anomalie détectée par le cosinus.
	    <br>
	    la proportion de variance cumulée indique qu'il faut utiliser 3 ou 4 dimensions pour obtenir une représentation correcte.
	    <br>
	    <img src="villes.prop_variance_cumulée.png" width="400pt" alt="" />
	    <br>
	    D'après vous, quels sont les problèmes rencontrés sur ce jeu de données pour réaliser une projection en 2D fidèle à la réalité à l'aide d'une ACP&nbsp;?
	    <br>
	    Remarque&nbsp;: outre les problèmes auxquels je vous encourage de réfléchir que je mentionne ci-dessus, il faut savoir qu'une matrice de distances entre objets est un objet mathématique particulier et que pour en réaliser une ACP, la méthode est légérement différente de celle que l'on a vue qui concerne les données tabulaires (des individus décrits par des attributs). J'ai posé cet exercice parce que néanmoins, il est intéressant que vous rencontriez ce type de données et, on peut toujours essayer d'en faire une ACP. C'est aussi le problème de la science des données&nbsp;: une méthode, même si elle n'est pas adaptée, donne toujours un résultat. Seulement, si la méthode n'est pas adaptée (et ce n'est pas toujours évident de savoir si une méthode est ou non adaptée à un type de données ou pour étudier une certaine question), on obtient un résultat qui n'a pas de sens.
	  </div>
	</li>
	<li><a href="https://philippe-preux.github.io/ensg/miashs/datasets/26letters.txt">Ce fichier</a> contient une matrice qui indique le nombre d'occurrences de chacune des 26 lettres de l'alphabet latin dans un même texte (issu de la constitution européenne) traduit dans 19 langues européennes. Il est intéressant d'en faire une ACP et de projeter les langues dans le plan principal afin de visualiser leur proximité en terme de fréquence d'apparition de chacune des lettres. Par contre, pour ce jeu de données, il faut réaliser un pré-traitement des données pour que l'ACP ait un sens&nbsp;: lequel&nbsp;?
	  <br>
	  <div class="correction">
	    Le nombre d'occurences des lettres n'a pas de sens. Ce qui a un sens est leur fréquence d'apparition. Il faut donc transformer les effectifs en fréquence. Pour chaque langue, on divise donc les effectifs des 26 lettres par le nombre total de lettres composant le texte dans cette langue.
	  </div>
	  <br>
	  Comme ci-dessus pour les villes, afficher le nom des langues. En fonction de vos connaissances (même limitée) en linguistique, cette projection en 2D vous paraît-elle pertinente&nbsp;? Il est également intéressant de projeter les lettres dans le plan principal pour visualiser leur proximité en fonction de leur utilisation dans ces 19 langues européennes. Faites le graphique correspondant. Comment pouvez-vous déterminer si cette représentation en 2D est fidèle au jeu de données&nbsp;?

	  <div class="correction">
	    Il n'y a aucune difficulté, c'est toujours la même chose.
	    <br>
	    Pour les langues, j'obtiens la proportion de variance cumulée et la projection dans le plan principal ci-dessous.
	    <br>
	    <img src="langues.prop_variance_cumulée.png" width="400pt" alt="pvc" />
	    <img src="langues.plan-principal.avec-anomalies.png" width="400pt" alt="1x2" />
	    <br>
	    Le graphique de gauche indique très clairement que la projection en deux dimensions a peu de chance d'être fidèle. En rouge sont indiquées les langues qui sont mal projetées dans le plan principal («&nbsp;mal&nbsp;» projetés au sens du cosinus). Trouver parmi celles-ci le hongrois (hu) n'est pas très étonnant car on sait que la langue hongroise n'est pas une langue indo-européenne&nbsp;; par contre, c'est vrai aussi du finnois qui lui est correctement projeté. Le français et l'italien, deux langues très proches, sont mal projetées dans le plan principal. Par contre, voir un regroupement allemand, danois, néerlandais et anglais est cohérent. Mais ce graphique est à interprêter avec la plus grande prudence étant donné le graphique de gauche.
	    <br>
	    On procède de la même manière pour les lettres. J'obtiens la proportion de variance cumulée et la projection dans le plan principal ci-dessous.
	    <br>
	    <img src="lettres.prop_variance_cumulée.png" width="400pt" alt="pvc" />
	    <img src="lettres.plan-principal.avec-anomalies.png" width="400pt" alt="1x2" />
	    <br>
	    Cette fois-ci, le graphique de gauche indique très clairement que la projection en deux dimensions est assez fidèle. En rouge sont indiquées les lettres qui sont mal projetées dans le plan principal.
	  </div>

	</li>
	<li>En classification supervisée, il arrive parfois que le taux de succès augmente quand on pré-traite les données au moyen d'une ACP. Tester cette idée sur les iris. Que constatez-vous&nbsp;?
	  <div class="correction">
	    Là encore, aucune difficulté. On constate que l'arbre construit avec la représentation factorielle des iris obtient un score (légérement) meilleur que celui construit avec les attributs originaux.
	  </div>
	</li>
      </ul>
      
    </div>

<!-- Default Statcounter code for on github
https://philippe-preux.github.io -->
<script>
  var sc_project=12923547; 
  var sc_invisible=1; 
  var sc_security="627600d4"; 
</script>
<script src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript>
  <div class="statcounter">
    <a title="Web Analytics" href="https://statcounter.com/" target="_blank">
      <img class="statcounter"
	   src="https://c.statcounter.com/12923547/0/627600d4/1/"
	   alt="Web Analytics"
	   referrerPolicy="no-referrer-when-downgrade"></a>
  </div>
</noscript>
  <!-- End of Statcounter Code -->
  
</body>
</html>
